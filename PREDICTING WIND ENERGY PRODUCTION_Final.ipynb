{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07e4b7a8",
   "metadata": {},
   "source": [
    "## PREDICTING WIND ENERGY PRODUCTION\n",
    "\n",
    "The objetive of this project is to develop a machine learing model for estimating how much energy is going to be produced at the Sotavento experimental wind farm. To do it, we will use meteorological variables forecasted by ECMWF (http://www.ecmwf.int/) as input attributes. We have 22 variables, but, it is common practice to use the value of those variables, not just at the location of interest (Sotavento in this case), but at points in a grid around Sotavento. A 5x5 grid will be used in this case. Important to have in mind that the values at point 13 are the ones exactly Sotavento.Therefore, finally we have 550 variables (plus other 5 measuring energy, year, month, day and hour). The 22 variables are described as follows: \n",
    "\n",
    "- t2m: 2 metre temperature\n",
    "- u10: 10 metre U wind component\n",
    "- v10: 10 metre V wind component\n",
    "- u100: 100 metre U wind component\n",
    "- v100: 100 metre V wind component\n",
    "- cape: Convective available potential energy\n",
    "- flsr: Forecast logarithm of surface roughness for heat\n",
    "- fsr: Forecast surface roughness\n",
    "- iews: Instantaneous eastward turbulent surface stress\n",
    "- inss: Instantaneous northward turbulent surface\n",
    "- lai_hv: Leaf area index, high vegetation\n",
    "- lai_lv: Leaf area index, low vegetation\n",
    "- u10n: Neutral wind at 10 m u-component\n",
    "- v10n: Neutral wind at 10 m v-component\n",
    "- stl1: Soil temperature level 1\n",
    "- stl2: Soil temperature level 2\n",
    "- stl3: Soil temperature level 3\n",
    "- stl4: Soil temperature level 4\n",
    "- sp: Surface pressure\n",
    "- p54.162: Vertical integral of temperature\n",
    "- p59.162: Vertical integral of divergence of kinetic energy\n",
    "- p55.162: Vertical integral of water vapour\n",
    "\n",
    "\n",
    "First, we load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a8a8d1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns  \n",
    "from sklearn.model_selection import train_test_split, PredefinedSplit, GridSearchCV, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer, KNNImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler, StandardScaler\n",
    "from sklearn.dummy import DummyRegressor\n",
    "import time\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from skopt.space import Integer\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "39f6bdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wind_ava = pd.read_csv(\"C:\\\\Users\\\\victoria\\\\Escritorio\\\\MASTER\\\\Big Data Intelligence\\\\Assignment_1\\\\Big_Data_Intelligence\\\\wind_available.csv.gzip\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8a9e684b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pongo aqui abajo mi path \n",
    "\n",
    "wind_ava = pd.read_csv(\"/Users/pameladiaz/Desktop/GitHub/Big_Data_Intelligence/wind_available.csv.gzip\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b98d0c",
   "metadata": {},
   "source": [
    "## 1. Exploratory Data Analysis\n",
    "\n",
    "It is important before starting any machine learning project to observe and understand the data we have. Therefore, during this section we will be exploring how many features and how many instances the dataset has, which variables are categorical / numerical, which features have missing values and how many, whether there are constant columns, some statistics, and whether it is a regression or classification problem. \n",
    "\n",
    "Finally, we will plot some of the variables in terms of the target for trying to find some relations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e17857",
   "metadata": {},
   "source": [
    "### 1.1. Number of features\n",
    "\n",
    "As previosly explained, the dataset contains 555 variables and 4747 instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa66419a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>energy</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>p54.162.1</th>\n",
       "      <th>p54.162.2</th>\n",
       "      <th>p54.162.3</th>\n",
       "      <th>p54.162.4</th>\n",
       "      <th>p54.162.5</th>\n",
       "      <th>...</th>\n",
       "      <th>v100.16</th>\n",
       "      <th>v100.17</th>\n",
       "      <th>v100.18</th>\n",
       "      <th>v100.19</th>\n",
       "      <th>v100.20</th>\n",
       "      <th>v100.21</th>\n",
       "      <th>v100.22</th>\n",
       "      <th>v100.23</th>\n",
       "      <th>v100.24</th>\n",
       "      <th>v100.25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>402.71</td>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>2.534970e+06</td>\n",
       "      <td>2.526864e+06</td>\n",
       "      <td>2.518754e+06</td>\n",
       "      <td>2.510648e+06</td>\n",
       "      <td>2.502537e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.683596</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.407196</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.131295</td>\n",
       "      <td>-4.669626</td>\n",
       "      <td>-4.528932</td>\n",
       "      <td>-4.388736</td>\n",
       "      <td>-4.248540</td>\n",
       "      <td>-4.107846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>696.80</td>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.521184e+06</td>\n",
       "      <td>2.513088e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.397886</td>\n",
       "      <td>-3.257192</td>\n",
       "      <td>-3.115998</td>\n",
       "      <td>-2.975304</td>\n",
       "      <td>-2.834609</td>\n",
       "      <td>-3.396390</td>\n",
       "      <td>-3.254198</td>\n",
       "      <td>-3.112506</td>\n",
       "      <td>-2.970314</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1591.15</td>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2.533727e+06</td>\n",
       "      <td>2.525703e+06</td>\n",
       "      <td>2.517678e+06</td>\n",
       "      <td>2.509654e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.454105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.138290</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.822476</td>\n",
       "      <td>-1.459094</td>\n",
       "      <td>-1.302933</td>\n",
       "      <td>-1.147271</td>\n",
       "      <td>-0.991110</td>\n",
       "      <td>-0.834949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1338.62</td>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.526548e+06</td>\n",
       "      <td>2.518609e+06</td>\n",
       "      <td>2.510670e+06</td>\n",
       "      <td>2.502732e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.255015</td>\n",
       "      <td>1.370265</td>\n",
       "      <td>1.485515</td>\n",
       "      <td>1.600765</td>\n",
       "      <td>1.716015</td>\n",
       "      <td>1.210612</td>\n",
       "      <td>1.319376</td>\n",
       "      <td>1.428140</td>\n",
       "      <td>1.536405</td>\n",
       "      <td>1.645169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>562.50</td>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>2.529543e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.513702e+06</td>\n",
       "      <td>2.505782e+06</td>\n",
       "      <td>2.497861e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.939031</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.193977</td>\n",
       "      <td>2.278793</td>\n",
       "      <td>1.873673</td>\n",
       "      <td>1.953000</td>\n",
       "      <td>2.031829</td>\n",
       "      <td>2.111157</td>\n",
       "      <td>2.189986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4743</th>\n",
       "      <td>1280.13</td>\n",
       "      <td>2009</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.400131e+06</td>\n",
       "      <td>2.393033e+06</td>\n",
       "      <td>2.385939e+06</td>\n",
       "      <td>2.378841e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>9.377886</td>\n",
       "      <td>9.271118</td>\n",
       "      <td>9.164849</td>\n",
       "      <td>9.058080</td>\n",
       "      <td>8.951312</td>\n",
       "      <td>9.402832</td>\n",
       "      <td>9.291075</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.068059</td>\n",
       "      <td>8.956800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4744</th>\n",
       "      <td>855.00</td>\n",
       "      <td>2009</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>2.407234e+06</td>\n",
       "      <td>2.400117e+06</td>\n",
       "      <td>2.393001e+06</td>\n",
       "      <td>2.385885e+06</td>\n",
       "      <td>2.378768e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345796</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.655624</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.964953</td>\n",
       "      <td>7.457055</td>\n",
       "      <td>7.604734</td>\n",
       "      <td>7.751915</td>\n",
       "      <td>7.899595</td>\n",
       "      <td>8.047274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4745</th>\n",
       "      <td>117.06</td>\n",
       "      <td>2009</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>18</td>\n",
       "      <td>2.401034e+06</td>\n",
       "      <td>2.393683e+06</td>\n",
       "      <td>2.386332e+06</td>\n",
       "      <td>2.378981e+06</td>\n",
       "      <td>2.371630e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>3.485674</td>\n",
       "      <td>3.535566</td>\n",
       "      <td>3.585458</td>\n",
       "      <td>3.635349</td>\n",
       "      <td>3.685241</td>\n",
       "      <td>3.505132</td>\n",
       "      <td>3.552030</td>\n",
       "      <td>3.598429</td>\n",
       "      <td>3.645328</td>\n",
       "      <td>3.691727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4746</th>\n",
       "      <td>516.96</td>\n",
       "      <td>2009</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>12</td>\n",
       "      <td>2.393873e+06</td>\n",
       "      <td>2.386499e+06</td>\n",
       "      <td>2.379125e+06</td>\n",
       "      <td>2.371752e+06</td>\n",
       "      <td>2.364378e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.988424</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.529749</td>\n",
       "      <td>1.960983</td>\n",
       "      <td>2.094194</td>\n",
       "      <td>2.226906</td>\n",
       "      <td>2.360117</td>\n",
       "      <td>2.492829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4747</th>\n",
       "      <td>867.07</td>\n",
       "      <td>2009</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>18</td>\n",
       "      <td>2.392305e+06</td>\n",
       "      <td>2.384669e+06</td>\n",
       "      <td>2.377033e+06</td>\n",
       "      <td>2.369398e+06</td>\n",
       "      <td>2.361766e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>2.052784</td>\n",
       "      <td>2.017860</td>\n",
       "      <td>1.982437</td>\n",
       "      <td>1.947512</td>\n",
       "      <td>1.912089</td>\n",
       "      <td>2.064259</td>\n",
       "      <td>2.031829</td>\n",
       "      <td>1.998901</td>\n",
       "      <td>1.966471</td>\n",
       "      <td>1.934042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4748 rows × 555 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       energy  year  month  day  hour     p54.162.1     p54.162.2  \\\n",
       "0      402.71  2005      1    2    18  2.534970e+06  2.526864e+06   \n",
       "1      696.80  2005      1    3     0           NaN           NaN   \n",
       "2     1591.15  2005      1    3     6  2.533727e+06  2.525703e+06   \n",
       "3     1338.62  2005      1    3    12           NaN  2.526548e+06   \n",
       "4      562.50  2005      1    3    18  2.529543e+06           NaN   \n",
       "...       ...   ...    ...  ...   ...           ...           ...   \n",
       "4743  1280.13  2009     12   30     6           NaN  2.400131e+06   \n",
       "4744   855.00  2009     12   30    12  2.407234e+06  2.400117e+06   \n",
       "4745   117.06  2009     12   30    18  2.401034e+06  2.393683e+06   \n",
       "4746   516.96  2009     12   31    12  2.393873e+06  2.386499e+06   \n",
       "4747   867.07  2009     12   31    18  2.392305e+06  2.384669e+06   \n",
       "\n",
       "         p54.162.3     p54.162.4     p54.162.5  ...   v100.16   v100.17  \\\n",
       "0     2.518754e+06  2.510648e+06  2.502537e+06  ... -4.683596       NaN   \n",
       "1     2.521184e+06  2.513088e+06           NaN  ... -3.397886 -3.257192   \n",
       "2     2.517678e+06  2.509654e+06           NaN  ... -1.454105       NaN   \n",
       "3     2.518609e+06  2.510670e+06  2.502732e+06  ...  1.255015  1.370265   \n",
       "4     2.513702e+06  2.505782e+06  2.497861e+06  ...  1.939031       NaN   \n",
       "...            ...           ...           ...  ...       ...       ...   \n",
       "4743  2.393033e+06  2.385939e+06  2.378841e+06  ...  9.377886  9.271118   \n",
       "4744  2.393001e+06  2.385885e+06  2.378768e+06  ...  7.345796       NaN   \n",
       "4745  2.386332e+06  2.378981e+06  2.371630e+06  ...  3.485674  3.535566   \n",
       "4746  2.379125e+06  2.371752e+06  2.364378e+06  ...  1.988424       NaN   \n",
       "4747  2.377033e+06  2.369398e+06  2.361766e+06  ...  2.052784  2.017860   \n",
       "\n",
       "       v100.18   v100.19   v100.20   v100.21   v100.22   v100.23   v100.24  \\\n",
       "0    -4.407196       NaN -4.131295 -4.669626 -4.528932 -4.388736 -4.248540   \n",
       "1    -3.115998 -2.975304 -2.834609 -3.396390 -3.254198 -3.112506 -2.970314   \n",
       "2    -1.138290       NaN -0.822476 -1.459094 -1.302933 -1.147271 -0.991110   \n",
       "3     1.485515  1.600765  1.716015  1.210612  1.319376  1.428140  1.536405   \n",
       "4          NaN  2.193977  2.278793  1.873673  1.953000  2.031829  2.111157   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4743  9.164849  9.058080  8.951312  9.402832  9.291075       NaN  9.068059   \n",
       "4744  7.655624       NaN  7.964953  7.457055  7.604734  7.751915  7.899595   \n",
       "4745  3.585458  3.635349  3.685241  3.505132  3.552030  3.598429  3.645328   \n",
       "4746       NaN       NaN  2.529749  1.960983  2.094194  2.226906  2.360117   \n",
       "4747  1.982437  1.947512  1.912089  2.064259  2.031829  1.998901  1.966471   \n",
       "\n",
       "       v100.25  \n",
       "0    -4.107846  \n",
       "1          NaN  \n",
       "2    -0.834949  \n",
       "3     1.645169  \n",
       "4     2.189986  \n",
       "...        ...  \n",
       "4743  8.956800  \n",
       "4744  8.047274  \n",
       "4745  3.691727  \n",
       "4746  2.492829  \n",
       "4747  1.934042  \n",
       "\n",
       "[4748 rows x 555 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 10)\n",
    "wind_ava"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c4c01a",
   "metadata": {},
   "source": [
    "### 1.2. Variable type\n",
    "\n",
    "All the variables we are dealing with are numerical, most of them continuous and only the ones specifiying the time when the measure was taken (year, month, day and hour) are of type integer. This leaves us with a regression problem, as the target variable 'energy' is a continuous numerical variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90498a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "wind_ava.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f0ccf6",
   "metadata": {},
   "source": [
    "### 1.3. Missing values\n",
    "\n",
    "If any of the variables has many missing values (more than 80%) we should remove it. After checking it, we are sure none of them  has more than 80% nulls, the maximum is 20.3 % for the variable lai_hv.13 (Leaf area index, high vegetation, section 13, Sotavento). It is difficult to determine the reason most of the variables has nulls, as we are not experts on the field. We will try to solve this later on the preprocessing with imputation methods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51110864",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_percentage = wind_ava.isnull().sum()/ len(wind_ava) * 100\n",
    "print(null_percentage[null_percentage > 80])\n",
    "print(max(null_percentage))\n",
    "null_percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cbe473",
   "metadata": {},
   "source": [
    "### 1.4. Statistics\n",
    "\n",
    "As all of our variables are numeric, we can perform a statistical analysis by giving some information about the mean, standard deviation, quantiles etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68935e6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wind_ava.describe().T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058db2fc",
   "metadata": {},
   "source": [
    "### 1.5. Constant columns\n",
    "\n",
    "Similarly with the null values, if any column has constant values, this gives no information to the final model, so it should be removed. Taking into account that some variables have null values, we should look if the number of unique values is less or equal to 2 (the constant value and Nan). As is not the case, we don't have any column with constant values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dfc856",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(wind_ava.nunique() <= 2)\n",
    "#wind_ava.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b51b23b",
   "metadata": {},
   "source": [
    "### 1.6. Visualization\n",
    "\n",
    "Let's observe first how the objective variable looks. It follows an exponential distribution, as most of the values are around the highest energy production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170871c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 10)\n",
    "\n",
    "plt.hist(wind_ava['energy'],  bins=30, color='skyblue', edgecolor='black')\n",
    "plt.title(f'Energy histogram')\n",
    "plt.xlabel('Energy value')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Muestra el histograma\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3587ec38",
   "metadata": {},
   "source": [
    "We could also observe the mean enery production per year. As observed,  most of the years have similar energy production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94431d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean energy per year\n",
    "mean_energy = wind_ava.groupby('year')['energy'].mean()\n",
    "\n",
    "# Barplot\n",
    "plt.figure(figsize=(10, 5))  # Ajusta el tamaño del gráfico según tus preferencias\n",
    "mean_energy.plot(kind='bar', color='skyblue', edgecolor='black')\n",
    "\n",
    "# Graph\n",
    "plt.title('Energy produced per year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Energy')\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3436a8",
   "metadata": {},
   "source": [
    "Similarly, we could observe the mean energy production per month. This plot give us more valuable information, becuase, as it could be expected, on the months of worst weather and more wind, the energy production is highly increased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3d9bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_energy = wind_ava.groupby('month')['energy'].mean()\n",
    "\n",
    "plt.figure(figsize=(10, 5))  \n",
    "mean_energy.plot(kind='bar', color='skyblue', edgecolor='black')\n",
    "\n",
    "plt.title('Mean energy produced per month')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Energy')\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b72516",
   "metadata": {},
   "source": [
    "### 1.7. Feature transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68ce285",
   "metadata": {},
   "source": [
    "Althought we have many variables, it is understandable that the variables u100 (100 metre U wind component) and v100 (100 metre V wind component) give us the most valuable information. However, the modullus is more valuable, as measures the wind speed at 100 meters high. Therefore, we would add this as a new variable to our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "86e5ee4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>energy</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>p54.162.1</th>\n",
       "      <th>p54.162.2</th>\n",
       "      <th>p54.162.3</th>\n",
       "      <th>p54.162.4</th>\n",
       "      <th>p54.162.5</th>\n",
       "      <th>...</th>\n",
       "      <th>wind_speed16</th>\n",
       "      <th>wind_speed17</th>\n",
       "      <th>wind_speed18</th>\n",
       "      <th>wind_speed19</th>\n",
       "      <th>wind_speed20</th>\n",
       "      <th>wind_speed21</th>\n",
       "      <th>wind_speed22</th>\n",
       "      <th>wind_speed23</th>\n",
       "      <th>wind_speed24</th>\n",
       "      <th>wind_speed25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>402.71</td>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>2.534970e+06</td>\n",
       "      <td>2.526864e+06</td>\n",
       "      <td>2.518754e+06</td>\n",
       "      <td>2.510648e+06</td>\n",
       "      <td>2.502537e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>5.134636</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.393808</td>\n",
       "      <td>5.137268</td>\n",
       "      <td>4.948249</td>\n",
       "      <td>4.760744</td>\n",
       "      <td>4.574870</td>\n",
       "      <td>4.389944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>696.80</td>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.521184e+06</td>\n",
       "      <td>2.513088e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5.298553</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.869726</td>\n",
       "      <td>4.655077</td>\n",
       "      <td>4.440835</td>\n",
       "      <td>5.300003</td>\n",
       "      <td>5.085998</td>\n",
       "      <td>4.872320</td>\n",
       "      <td>4.658335</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1591.15</td>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2.533727e+06</td>\n",
       "      <td>2.525703e+06</td>\n",
       "      <td>2.517678e+06</td>\n",
       "      <td>2.509654e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5.587899</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.529130</td>\n",
       "      <td>5.324473</td>\n",
       "      <td>5.122190</td>\n",
       "      <td>4.922326</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1338.62</td>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.526548e+06</td>\n",
       "      <td>2.518609e+06</td>\n",
       "      <td>2.510670e+06</td>\n",
       "      <td>2.502732e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>4.779456</td>\n",
       "      <td>4.715311</td>\n",
       "      <td>4.655777</td>\n",
       "      <td>4.600019</td>\n",
       "      <td>4.549180</td>\n",
       "      <td>4.698198</td>\n",
       "      <td>4.634036</td>\n",
       "      <td>4.573135</td>\n",
       "      <td>4.516475</td>\n",
       "      <td>4.463542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>562.50</td>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>2.529543e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.513702e+06</td>\n",
       "      <td>2.505782e+06</td>\n",
       "      <td>2.497861e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>3.941046</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.917355</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.851946</td>\n",
       "      <td>3.843097</td>\n",
       "      <td>3.836565</td>\n",
       "      <td>3.832704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 580 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    energy  year  month  day  hour     p54.162.1     p54.162.2     p54.162.3  \\\n",
       "0   402.71  2005      1    2    18  2.534970e+06  2.526864e+06  2.518754e+06   \n",
       "1   696.80  2005      1    3     0           NaN           NaN  2.521184e+06   \n",
       "2  1591.15  2005      1    3     6  2.533727e+06  2.525703e+06  2.517678e+06   \n",
       "3  1338.62  2005      1    3    12           NaN  2.526548e+06  2.518609e+06   \n",
       "4   562.50  2005      1    3    18  2.529543e+06           NaN  2.513702e+06   \n",
       "\n",
       "      p54.162.4     p54.162.5  ...  wind_speed16  wind_speed17  wind_speed18  \\\n",
       "0  2.510648e+06  2.502537e+06  ...      5.134636           NaN           NaN   \n",
       "1  2.513088e+06           NaN  ...      5.298553           NaN      4.869726   \n",
       "2  2.509654e+06           NaN  ...      5.587899           NaN           NaN   \n",
       "3  2.510670e+06  2.502732e+06  ...      4.779456      4.715311      4.655777   \n",
       "4  2.505782e+06  2.497861e+06  ...      3.941046           NaN           NaN   \n",
       "\n",
       "   wind_speed19  wind_speed20  wind_speed21  wind_speed22  wind_speed23  \\\n",
       "0           NaN      4.393808      5.137268      4.948249      4.760744   \n",
       "1      4.655077      4.440835      5.300003      5.085998      4.872320   \n",
       "2           NaN           NaN      5.529130      5.324473      5.122190   \n",
       "3      4.600019      4.549180      4.698198      4.634036      4.573135   \n",
       "4      3.917355           NaN           NaN      3.851946      3.843097   \n",
       "\n",
       "   wind_speed24  wind_speed25  \n",
       "0      4.574870      4.389944  \n",
       "1      4.658335           NaN  \n",
       "2      4.922326           NaN  \n",
       "3      4.516475      4.463542  \n",
       "4      3.836565      3.832704  \n",
       "\n",
       "[5 rows x 580 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_wind_columns = wind_ava.columns[wind_ava.columns.str.startswith('v100.')]\n",
    "u_wind_columns = wind_ava.columns[wind_ava.columns.str.startswith('u100.')]\n",
    "\n",
    "# Iterate through pairs of u and v columns\n",
    "for u_col, v_col in zip(u_wind_columns, v_wind_columns):\n",
    "    # Extract u and v components\n",
    "    u_component = wind_ava[u_col]\n",
    "    v_component = wind_ava[v_col]\n",
    "\n",
    "    # Calculate wind speed\n",
    "    wind_speed_col = f\"wind_speed{u_col.split('.')[1]}\"\n",
    "    wind_ava[wind_speed_col] = np.sqrt(u_component**2 + v_component**2)\n",
    "\n",
    "# Display the modified DataFrame with new wind speed columns\n",
    "wind_ava.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3581b4c",
   "metadata": {},
   "source": [
    "As can be observed, this new variable againts the response variable follows a linear relation, so it will give us valuable information when modelling the predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d79fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "# Obtain the columns defining the u and v components of the wind \n",
    "wind_speed_columns = wind_ava.columns[wind_ava.columns.str.startswith('wind_speed')]\n",
    "\n",
    " \n",
    "plt.scatter(wind_ava['energy'], wind_ava[wind_speed_columns].mean(axis=1), c='skyblue')\n",
    "plt.xlabel('Energy')\n",
    "plt.ylabel('Mean wind speed')\n",
    "plt.title('U and V wind components vs Energy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571dd698",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "042a7871",
   "metadata": {},
   "source": [
    "## 2. Inner, outer evaluation and metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded8192d",
   "metadata": {},
   "source": [
    "### 2.1. Holdout split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c768dc42",
   "metadata": {},
   "source": [
    "After a exploration of our dataset, the next crucial step was to select the evaluation strategy. Given the considerable volume of data at our disposal, we decided to perform a holdout strategy for both inner and outer evaluations. Cross-validation was not used because it is more computationally intensive and time-consuming, particularly in the context of our substantial dataset. \n",
    "\n",
    "Moreover, a key factor influencing our choice is the intrinsic nature of our data, a time series with dependencies that render it non-independent and non-identically distributed (non-i.i.d.). Consequently, we have employed a partitioning strategy based on complete years. This approach ensures that each partition is not only representative of the problem at hand but also respects the temporal dependencies inherent in the data.\n",
    "\n",
    "Visualizing the dataset through plots further informed our decision-making. Notably, for the year 2008, data is available only for January and February, whereas in 2009, we have a dataset spanning from March to December. To ensure a representative evaluation, we opted to combine the data from these two years, designating them as the test partition. The remaining years were used for training.\n",
    "\n",
    "Later on, within our training data, we took another step and split it into two parts: train-validation and train-train. We used the data from 2007 for train-validation, while 2005 and 2006 became the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60b4f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "plt.bar(wind_ava['year'].value_counts().index, wind_ava['year'].value_counts().values, color='skyblue', edgecolor='black')\n",
    "plt.title(f'Year barplot')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Show histogram\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef69791",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get unique years in the DataFrame\n",
    "unique_years = wind_ava['year'].unique()\n",
    "\n",
    "# Set up subplots\n",
    "fig, axes = plt.subplots(nrows=len(unique_years), ncols=1, figsize=(8, 5 * len(unique_years)))\n",
    "\n",
    "# Loop through each year and create a bar plot for the frequency of each month\n",
    "for i, year in enumerate(unique_years):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Filter data for the current year\n",
    "    data_year = wind_ava[wind_ava['year'] == year]\n",
    "    \n",
    "    # Create a count plot for the 'month' column\n",
    "    sns.countplot(x='month', data=data_year, ax=ax, palette='viridis')\n",
    "    \n",
    "    # Customize the plot\n",
    "    ax.set_title(f'Monthly Frequency for the Year {year}')\n",
    "    ax.set_xlabel('Month')\n",
    "    ax.set_ylabel('Frequency')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f3fd0c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and test sets\n",
    "train_data = wind_ava[wind_ava['year'].isin([2005, 2006, 2007])]\n",
    "test_data = wind_ava[wind_ava['year'].isin([2008, 2009])]\n",
    "\n",
    "# Further split the training set into train-train and train-validation\n",
    "train_train_data = train_data[train_data['year'].isin([2005, 2006])]\n",
    "train_validation_data = train_data[train_data['year'] == 2007]\n",
    "\n",
    "\n",
    "# Features and target for training set\n",
    "X_train_train = train_train_data.drop('energy', axis=1)\n",
    "#y_train_train = train_train_data['energy']\n",
    "\n",
    "X_train = train_data.drop('energy', axis=1)\n",
    "y_train = train_data['energy']\n",
    "\n",
    "\n",
    "# Features and target for validation set\n",
    "X_train_validation = train_validation_data.drop('energy', axis=1)\n",
    "#y_train_validation = train_validation_data['energy']\n",
    "\n",
    "# Features and target for test set\n",
    "X_test = test_data.drop('energy', axis=1)\n",
    "y_test = test_data['energy']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7968af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#X_train_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd1d7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc34a5c",
   "metadata": {},
   "source": [
    "### 2.2. Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba00b51",
   "metadata": {},
   "source": [
    "CHAT GPT:\n",
    "The choice of which metric to use for evaluating a regression model depends on the specific characteristics of the problem and our goals. As a summary of the benefits and drawbacks of the most commonly used regression metrics:\n",
    "\n",
    "- Mean Squared Error (MSE) or Root Mean Squared Error (RMSE): These are often preferred when large errors should be penalized more heavily, and the distribution of errors is approximately normal. However, if your data contains outliers, MSE and RMSE can be significantly affected.\n",
    "\n",
    "- Mean Absolute Error (MAE): These are more robust to outliers. If your dataset has a skewed distribution or contains outliers, MAE might be more appropriate.\n",
    "\n",
    "Therefore, we will evaluate the outliers of our objetive variable to understand which metric is better on this problem. As observed, the data is rigth skewed, with many outliers on the rigth section, therefore, a MAE metric would affect less to these errors when predicting outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0847e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(train_train_data['energy'], vert=False, widths=0.7, patch_artist=True, boxprops=dict(facecolor='skyblue', color='black'))\n",
    "plt.title('Energy Boxplot')\n",
    "plt.xlabel('Energy value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526d21e4-bc5b-491c-a1cf-8ff78a60ee2d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 2.3. Strategy\n",
    "\n",
    "#### First plan\n",
    "\n",
    "Issues to address: \n",
    "- Feature selection: are all the 550 attributes really necessary? Maybe only the attributes related to the Sotavento location (13th location in the grid) are actually required? Or only the attributes related to wind? \r",
    "- Imputation: Does imputation improve performance in this problem? Which method seem to work best?- Modeling:s) Which method is more appropriate to the proble). Does hyper-parameter tuning contribute to improve performance? At what cost (compute tim?). Which HPO method does perform bette\n",
    "\n",
    "Strategy:\n",
    "\n",
    "The idea is to cover the first two issues on the data preprocessing, starting with the feature selection to reduce the data size as much as possible to make the later computations easier. During this preprocessing, on each stage, we compute a pipeline where we perform the necessary transformations (defining the adequate search space on each stage), and later, we predict with KNN regressor. This method was chosen due to its simplicity and a small number of hyperparameters (it was used on default mode, not HPO of KNN during the preprocessing). Apart from feature selection and imputation, scaling hyperparameters will also be tuned during this process. All this tuning will be done by performing a GridSearch over the hyperparameters in order to be more exhaustive, as the process of preprocessing is one of the most important parts of the project. When preprocessing is finished, we will apply all the necessary transformations to the entire data to prepare it for the modeling.\n",
    "\n",
    "The next step is to evaluate different models/methods for the problem. First, we would define a naive model with the data median as the prediction. Secondly, we would address four methods: Trees, KNN, random forest, and gradient boosting regressor. All of them would be modeled both default and with HPO. Among HPO, it is difficult to try all the possible methods, so we have tried Random Search, Grid Search, Bayesian Search, and Successive Halving. All the metric results and time measurements would be kept for later comparison.\n",
    "\n",
    "#### Strategy modifications\n",
    "\n",
    "The initial approach employed for hyperparameter optimization in Random Forest and Gradient Boosting involved using Random Search. However, it became apparent that this method consumed considerable time due to the escalating number of trees and the resultant model complexity. Drawing insights from the training of trees in the preceding steps, it was observed that both Grid Search and Bayesian Search required even more time than Random Search, with minimal improvement in Mean Absolute Error (MAE).\n",
    "\n",
    "Given that Random Forest and Gradient Boosting are ensemble models built on tree-based structures, one might anticipate a similar trend, potentially exacerbated by the substantial increase in computing time introduced by Random Search. Consequently, the decision was made to forgo HPO attempts with Grid Search or Bayesian Search, as the anticipated benefits in terms of model performance did not justify the additional computational expense.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d87236f",
   "metadata": {},
   "source": [
    "## 3. Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c30737",
   "metadata": {},
   "source": [
    "### 3.1. Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cd7a7d-7402-4650-b164-fd667b4c39ba",
   "metadata": {},
   "source": [
    "In predictive modeling, not all columns or features may be necessary, and including irrelevant or redundant ones poses several challenges. The curse of dimensionality arises when a large number of features contribute to overfitting and increased computational complexity, requiring more data for reliable estimates. Superfluous features hinder model interpretability and introduce noise, potentially leading to issues with data quality, missing values, and outliers. Feature selection becomes crucial in mitigating these challenges, helping to identify and retain the most informative features for building simpler and effective predictive models.\n",
    "\n",
    "In the initial stage of preprocessing, we prioritized feature selection as the first step, anticipating the subsequent use of the iterative imputer and aiming to optimize computational efficiency. To kickstart this process, we employed SimpleImputer for initial imputation, employing the default mean as the descriptive statistic to handle missing values. Concurrently, we introduced StandardScaler to prepare the data for feature selection. Our feature selection strategy involved leveraging SelectKBest, a sklearn method implementing univariate feature selection, which selects optimal features based on statistical tests. Within this phase, our objective was twofold: determining the ideal parameters for SelectKBest, encompassing the feature selection score function and the optimal number of features to select. Additionally, SelectKBest provided a valuable output – a mask or integer index – indicating the selected features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ec9267c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model MAE: 314.8766733393994\n"
     ]
    }
   ],
   "source": [
    "#We set a seed for reproducibility, althougth the split is predefined, some steps in all the pipelines defined may have some randomness\n",
    "random_state= 100516919\n",
    "\n",
    "# Load a sample dataset for demonstration\n",
    "X = X_train\n",
    "y = y_train\n",
    "\n",
    "# Define the holdout split\n",
    "indices= ([-1] * (len(X_train_train))) + ([0] * (len(X_train_validation)))\n",
    "inner= PredefinedSplit(indices)\n",
    "\n",
    "\n",
    "pipeline_feature_selection = Pipeline([\n",
    "    ('imputer', SimpleImputer()), \n",
    "    ('scaler', StandardScaler()),\n",
    "    ('feature_selection', SelectKBest()),  # Placeholder, will be replaced during grid search\n",
    "    ('knn', KNeighborsRegressor(n_jobs=-1))\n",
    "])\n",
    "\n",
    "# Define the hyperparameter grid for GridSearchCV\n",
    "param_grid_fs = {\n",
    "    'feature_selection__score_func': [f_regression, mutual_info_regression],\n",
    "    'feature_selection__k': [100,150,250,300,350]  # Adjust as needed\n",
    "}\n",
    "\n",
    "\n",
    "# Use GridSearchCV to find the best combination of parameters\n",
    "grid_search = GridSearchCV(pipeline_feature_selection, param_grid_fs, cv=inner, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Get the best model from the grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate and print the Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Best Model MAE: {mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e64e6a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'feature_selection__k': 250, 'feature_selection__score_func': <function mutual_info_regression at 0x1460c75e0>}\n"
     ]
    }
   ],
   "source": [
    "best_params = grid_search.best_params_\n",
    "print(f\"Best parameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a1af5c-c9d3-42e6-a89c-8521ad59f34d",
   "metadata": {},
   "source": [
    "## CAMBIO\n",
    "Con Random Search sale: \n",
    "Best parameters: {'feature_selection__score_func': <function mutual_info_regression at 0x1460c75e0>, 'feature_selection__k': 150}\n",
    "y cada vez que se runea sale un MAE diferente\n",
    "Asi que voy a poner el Grid Search otra vez porque con el Random sale todo distinto, y yo diria que la feature selection es lo mas importante osea cambia todo el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea32c2a-bc0d-43f2-a1c3-d8e6afa64bff",
   "metadata": {},
   "source": [
    "Con GridSearcHcv\n",
    "Best parameters: {'feature_selection__score_func': <function mutual_info_regression at 0x13f757310>, 'feature_selection__k': 250}\n",
    "Best Model MAE: 314.8766733393994\n",
    "y el error pues tambien sigue cambiando cada vez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c201f76e-e93f-4153-955a-68d428f36954",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f062b908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of selected features: [ 79  80  81  82  83  84  85  87  89  90  91  93  94  96 101 102 103 154\n",
      " 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172\n",
      " 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190\n",
      " 191 192 193 194 195 196 197 198 200 201 202 203 254 255 256 257 258 259\n",
      " 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277\n",
      " 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 294 295 296\n",
      " 297 298 299 300 301 302 303 379 380 381 382 383 384 385 386 387 388 389\n",
      " 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407\n",
      " 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425\n",
      " 426 427 428 479 480 481 484 485 486 487 488 489 490 504 505 506 507 508\n",
      " 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526\n",
      " 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544\n",
      " 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562\n",
      " 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578]\n"
     ]
    }
   ],
   "source": [
    "# Access the selected features\n",
    "selected_features = best_model.named_steps['feature_selection'].get_support()\n",
    "\n",
    "# Print the indices of selected features\n",
    "selected_feature_indices = np.where(selected_features)[0]\n",
    "print(f\"Indices of selected features: {selected_feature_indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6bc8a9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Label: year, Numerical Index: 0\n",
      "Column Label: month, Numerical Index: 1\n",
      "Column Label: day, Numerical Index: 2\n",
      "Column Label: hour, Numerical Index: 3\n",
      "Column Label: p54.162.1, Numerical Index: 4\n",
      "Column Label: p54.162.2, Numerical Index: 5\n",
      "Column Label: p54.162.3, Numerical Index: 6\n",
      "Column Label: p54.162.4, Numerical Index: 7\n",
      "Column Label: p54.162.5, Numerical Index: 8\n",
      "Column Label: p54.162.6, Numerical Index: 9\n",
      "Column Label: p54.162.7, Numerical Index: 10\n",
      "Column Label: p54.162.8, Numerical Index: 11\n",
      "Column Label: p54.162.9, Numerical Index: 12\n",
      "Column Label: p54.162.10, Numerical Index: 13\n",
      "Column Label: p54.162.11, Numerical Index: 14\n",
      "Column Label: p54.162.12, Numerical Index: 15\n",
      "Column Label: p54.162.13, Numerical Index: 16\n",
      "Column Label: p54.162.14, Numerical Index: 17\n",
      "Column Label: p54.162.15, Numerical Index: 18\n",
      "Column Label: p54.162.16, Numerical Index: 19\n",
      "Column Label: p54.162.17, Numerical Index: 20\n",
      "Column Label: p54.162.18, Numerical Index: 21\n",
      "Column Label: p54.162.19, Numerical Index: 22\n",
      "Column Label: p54.162.20, Numerical Index: 23\n",
      "Column Label: p54.162.21, Numerical Index: 24\n",
      "Column Label: p54.162.22, Numerical Index: 25\n",
      "Column Label: p54.162.23, Numerical Index: 26\n",
      "Column Label: p54.162.24, Numerical Index: 27\n",
      "Column Label: p54.162.25, Numerical Index: 28\n",
      "Column Label: p55.162.1, Numerical Index: 29\n",
      "Column Label: p55.162.2, Numerical Index: 30\n",
      "Column Label: p55.162.3, Numerical Index: 31\n",
      "Column Label: p55.162.4, Numerical Index: 32\n",
      "Column Label: p55.162.5, Numerical Index: 33\n",
      "Column Label: p55.162.6, Numerical Index: 34\n",
      "Column Label: p55.162.7, Numerical Index: 35\n",
      "Column Label: p55.162.8, Numerical Index: 36\n",
      "Column Label: p55.162.9, Numerical Index: 37\n",
      "Column Label: p55.162.10, Numerical Index: 38\n",
      "Column Label: p55.162.11, Numerical Index: 39\n",
      "Column Label: p55.162.12, Numerical Index: 40\n",
      "Column Label: p55.162.13, Numerical Index: 41\n",
      "Column Label: p55.162.14, Numerical Index: 42\n",
      "Column Label: p55.162.15, Numerical Index: 43\n",
      "Column Label: p55.162.16, Numerical Index: 44\n",
      "Column Label: p55.162.17, Numerical Index: 45\n",
      "Column Label: p55.162.18, Numerical Index: 46\n",
      "Column Label: p55.162.19, Numerical Index: 47\n",
      "Column Label: p55.162.20, Numerical Index: 48\n",
      "Column Label: p55.162.21, Numerical Index: 49\n",
      "Column Label: p55.162.22, Numerical Index: 50\n",
      "Column Label: p55.162.23, Numerical Index: 51\n",
      "Column Label: p55.162.24, Numerical Index: 52\n",
      "Column Label: p55.162.25, Numerical Index: 53\n",
      "Column Label: cape.1, Numerical Index: 54\n",
      "Column Label: cape.2, Numerical Index: 55\n",
      "Column Label: cape.3, Numerical Index: 56\n",
      "Column Label: cape.4, Numerical Index: 57\n",
      "Column Label: cape.5, Numerical Index: 58\n",
      "Column Label: cape.6, Numerical Index: 59\n",
      "Column Label: cape.7, Numerical Index: 60\n",
      "Column Label: cape.8, Numerical Index: 61\n",
      "Column Label: cape.9, Numerical Index: 62\n",
      "Column Label: cape.10, Numerical Index: 63\n",
      "Column Label: cape.11, Numerical Index: 64\n",
      "Column Label: cape.12, Numerical Index: 65\n",
      "Column Label: cape.13, Numerical Index: 66\n",
      "Column Label: cape.14, Numerical Index: 67\n",
      "Column Label: cape.15, Numerical Index: 68\n",
      "Column Label: cape.16, Numerical Index: 69\n",
      "Column Label: cape.17, Numerical Index: 70\n",
      "Column Label: cape.18, Numerical Index: 71\n",
      "Column Label: cape.19, Numerical Index: 72\n",
      "Column Label: cape.20, Numerical Index: 73\n",
      "Column Label: cape.21, Numerical Index: 74\n",
      "Column Label: cape.22, Numerical Index: 75\n",
      "Column Label: cape.23, Numerical Index: 76\n",
      "Column Label: cape.24, Numerical Index: 77\n",
      "Column Label: cape.25, Numerical Index: 78\n",
      "Column Label: p59.162.1, Numerical Index: 79\n",
      "Column Label: p59.162.2, Numerical Index: 80\n",
      "Column Label: p59.162.3, Numerical Index: 81\n",
      "Column Label: p59.162.4, Numerical Index: 82\n",
      "Column Label: p59.162.5, Numerical Index: 83\n",
      "Column Label: p59.162.6, Numerical Index: 84\n",
      "Column Label: p59.162.7, Numerical Index: 85\n",
      "Column Label: p59.162.8, Numerical Index: 86\n",
      "Column Label: p59.162.9, Numerical Index: 87\n",
      "Column Label: p59.162.10, Numerical Index: 88\n",
      "Column Label: p59.162.11, Numerical Index: 89\n",
      "Column Label: p59.162.12, Numerical Index: 90\n",
      "Column Label: p59.162.13, Numerical Index: 91\n",
      "Column Label: p59.162.14, Numerical Index: 92\n",
      "Column Label: p59.162.15, Numerical Index: 93\n",
      "Column Label: p59.162.16, Numerical Index: 94\n",
      "Column Label: p59.162.17, Numerical Index: 95\n",
      "Column Label: p59.162.18, Numerical Index: 96\n",
      "Column Label: p59.162.19, Numerical Index: 97\n",
      "Column Label: p59.162.20, Numerical Index: 98\n",
      "Column Label: p59.162.21, Numerical Index: 99\n",
      "Column Label: p59.162.22, Numerical Index: 100\n",
      "Column Label: p59.162.23, Numerical Index: 101\n",
      "Column Label: p59.162.24, Numerical Index: 102\n",
      "Column Label: p59.162.25, Numerical Index: 103\n",
      "Column Label: lai_lv.1, Numerical Index: 104\n",
      "Column Label: lai_lv.2, Numerical Index: 105\n",
      "Column Label: lai_lv.3, Numerical Index: 106\n",
      "Column Label: lai_lv.4, Numerical Index: 107\n",
      "Column Label: lai_lv.5, Numerical Index: 108\n",
      "Column Label: lai_lv.6, Numerical Index: 109\n",
      "Column Label: lai_lv.7, Numerical Index: 110\n",
      "Column Label: lai_lv.8, Numerical Index: 111\n",
      "Column Label: lai_lv.9, Numerical Index: 112\n",
      "Column Label: lai_lv.10, Numerical Index: 113\n",
      "Column Label: lai_lv.11, Numerical Index: 114\n",
      "Column Label: lai_lv.12, Numerical Index: 115\n",
      "Column Label: lai_lv.13, Numerical Index: 116\n",
      "Column Label: lai_lv.14, Numerical Index: 117\n",
      "Column Label: lai_lv.15, Numerical Index: 118\n",
      "Column Label: lai_lv.16, Numerical Index: 119\n",
      "Column Label: lai_lv.17, Numerical Index: 120\n",
      "Column Label: lai_lv.18, Numerical Index: 121\n",
      "Column Label: lai_lv.19, Numerical Index: 122\n",
      "Column Label: lai_lv.20, Numerical Index: 123\n",
      "Column Label: lai_lv.21, Numerical Index: 124\n",
      "Column Label: lai_lv.22, Numerical Index: 125\n",
      "Column Label: lai_lv.23, Numerical Index: 126\n",
      "Column Label: lai_lv.24, Numerical Index: 127\n",
      "Column Label: lai_lv.25, Numerical Index: 128\n",
      "Column Label: lai_hv.1, Numerical Index: 129\n",
      "Column Label: lai_hv.2, Numerical Index: 130\n",
      "Column Label: lai_hv.3, Numerical Index: 131\n",
      "Column Label: lai_hv.4, Numerical Index: 132\n",
      "Column Label: lai_hv.5, Numerical Index: 133\n",
      "Column Label: lai_hv.6, Numerical Index: 134\n",
      "Column Label: lai_hv.7, Numerical Index: 135\n",
      "Column Label: lai_hv.8, Numerical Index: 136\n",
      "Column Label: lai_hv.9, Numerical Index: 137\n",
      "Column Label: lai_hv.10, Numerical Index: 138\n",
      "Column Label: lai_hv.11, Numerical Index: 139\n",
      "Column Label: lai_hv.12, Numerical Index: 140\n",
      "Column Label: lai_hv.13, Numerical Index: 141\n",
      "Column Label: lai_hv.14, Numerical Index: 142\n",
      "Column Label: lai_hv.15, Numerical Index: 143\n",
      "Column Label: lai_hv.16, Numerical Index: 144\n",
      "Column Label: lai_hv.17, Numerical Index: 145\n",
      "Column Label: lai_hv.18, Numerical Index: 146\n",
      "Column Label: lai_hv.19, Numerical Index: 147\n",
      "Column Label: lai_hv.20, Numerical Index: 148\n",
      "Column Label: lai_hv.21, Numerical Index: 149\n",
      "Column Label: lai_hv.22, Numerical Index: 150\n",
      "Column Label: lai_hv.23, Numerical Index: 151\n",
      "Column Label: lai_hv.24, Numerical Index: 152\n",
      "Column Label: lai_hv.25, Numerical Index: 153\n",
      "Column Label: u10n.1, Numerical Index: 154\n",
      "Column Label: u10n.2, Numerical Index: 155\n",
      "Column Label: u10n.3, Numerical Index: 156\n",
      "Column Label: u10n.4, Numerical Index: 157\n",
      "Column Label: u10n.5, Numerical Index: 158\n",
      "Column Label: u10n.6, Numerical Index: 159\n",
      "Column Label: u10n.7, Numerical Index: 160\n",
      "Column Label: u10n.8, Numerical Index: 161\n",
      "Column Label: u10n.9, Numerical Index: 162\n",
      "Column Label: u10n.10, Numerical Index: 163\n",
      "Column Label: u10n.11, Numerical Index: 164\n",
      "Column Label: u10n.12, Numerical Index: 165\n",
      "Column Label: u10n.13, Numerical Index: 166\n",
      "Column Label: u10n.14, Numerical Index: 167\n",
      "Column Label: u10n.15, Numerical Index: 168\n",
      "Column Label: u10n.16, Numerical Index: 169\n",
      "Column Label: u10n.17, Numerical Index: 170\n",
      "Column Label: u10n.18, Numerical Index: 171\n",
      "Column Label: u10n.19, Numerical Index: 172\n",
      "Column Label: u10n.20, Numerical Index: 173\n",
      "Column Label: u10n.21, Numerical Index: 174\n",
      "Column Label: u10n.22, Numerical Index: 175\n",
      "Column Label: u10n.23, Numerical Index: 176\n",
      "Column Label: u10n.24, Numerical Index: 177\n",
      "Column Label: u10n.25, Numerical Index: 178\n",
      "Column Label: v10n.1, Numerical Index: 179\n",
      "Column Label: v10n.2, Numerical Index: 180\n",
      "Column Label: v10n.3, Numerical Index: 181\n",
      "Column Label: v10n.4, Numerical Index: 182\n",
      "Column Label: v10n.5, Numerical Index: 183\n",
      "Column Label: v10n.6, Numerical Index: 184\n",
      "Column Label: v10n.7, Numerical Index: 185\n",
      "Column Label: v10n.8, Numerical Index: 186\n",
      "Column Label: v10n.9, Numerical Index: 187\n",
      "Column Label: v10n.10, Numerical Index: 188\n",
      "Column Label: v10n.11, Numerical Index: 189\n",
      "Column Label: v10n.12, Numerical Index: 190\n",
      "Column Label: v10n.13, Numerical Index: 191\n",
      "Column Label: v10n.14, Numerical Index: 192\n",
      "Column Label: v10n.15, Numerical Index: 193\n",
      "Column Label: v10n.16, Numerical Index: 194\n",
      "Column Label: v10n.17, Numerical Index: 195\n",
      "Column Label: v10n.18, Numerical Index: 196\n",
      "Column Label: v10n.19, Numerical Index: 197\n",
      "Column Label: v10n.20, Numerical Index: 198\n",
      "Column Label: v10n.21, Numerical Index: 199\n",
      "Column Label: v10n.22, Numerical Index: 200\n",
      "Column Label: v10n.23, Numerical Index: 201\n",
      "Column Label: v10n.24, Numerical Index: 202\n",
      "Column Label: v10n.25, Numerical Index: 203\n",
      "Column Label: sp.1, Numerical Index: 204\n",
      "Column Label: sp.2, Numerical Index: 205\n",
      "Column Label: sp.3, Numerical Index: 206\n",
      "Column Label: sp.4, Numerical Index: 207\n",
      "Column Label: sp.5, Numerical Index: 208\n",
      "Column Label: sp.6, Numerical Index: 209\n",
      "Column Label: sp.7, Numerical Index: 210\n",
      "Column Label: sp.8, Numerical Index: 211\n",
      "Column Label: sp.9, Numerical Index: 212\n",
      "Column Label: sp.10, Numerical Index: 213\n",
      "Column Label: sp.11, Numerical Index: 214\n",
      "Column Label: sp.12, Numerical Index: 215\n",
      "Column Label: sp.13, Numerical Index: 216\n",
      "Column Label: sp.14, Numerical Index: 217\n",
      "Column Label: sp.15, Numerical Index: 218\n",
      "Column Label: sp.16, Numerical Index: 219\n",
      "Column Label: sp.17, Numerical Index: 220\n",
      "Column Label: sp.18, Numerical Index: 221\n",
      "Column Label: sp.19, Numerical Index: 222\n",
      "Column Label: sp.20, Numerical Index: 223\n",
      "Column Label: sp.21, Numerical Index: 224\n",
      "Column Label: sp.22, Numerical Index: 225\n",
      "Column Label: sp.23, Numerical Index: 226\n",
      "Column Label: sp.24, Numerical Index: 227\n",
      "Column Label: sp.25, Numerical Index: 228\n",
      "Column Label: stl1.1, Numerical Index: 229\n",
      "Column Label: stl1.2, Numerical Index: 230\n",
      "Column Label: stl1.3, Numerical Index: 231\n",
      "Column Label: stl1.4, Numerical Index: 232\n",
      "Column Label: stl1.5, Numerical Index: 233\n",
      "Column Label: stl1.6, Numerical Index: 234\n",
      "Column Label: stl1.7, Numerical Index: 235\n",
      "Column Label: stl1.8, Numerical Index: 236\n",
      "Column Label: stl1.9, Numerical Index: 237\n",
      "Column Label: stl1.10, Numerical Index: 238\n",
      "Column Label: stl1.11, Numerical Index: 239\n",
      "Column Label: stl1.12, Numerical Index: 240\n",
      "Column Label: stl1.13, Numerical Index: 241\n",
      "Column Label: stl1.14, Numerical Index: 242\n",
      "Column Label: stl1.15, Numerical Index: 243\n",
      "Column Label: stl1.16, Numerical Index: 244\n",
      "Column Label: stl1.17, Numerical Index: 245\n",
      "Column Label: stl1.18, Numerical Index: 246\n",
      "Column Label: stl1.19, Numerical Index: 247\n",
      "Column Label: stl1.20, Numerical Index: 248\n",
      "Column Label: stl1.21, Numerical Index: 249\n",
      "Column Label: stl1.22, Numerical Index: 250\n",
      "Column Label: stl1.23, Numerical Index: 251\n",
      "Column Label: stl1.24, Numerical Index: 252\n",
      "Column Label: stl1.25, Numerical Index: 253\n",
      "Column Label: u10.1, Numerical Index: 254\n",
      "Column Label: u10.2, Numerical Index: 255\n",
      "Column Label: u10.3, Numerical Index: 256\n",
      "Column Label: u10.4, Numerical Index: 257\n",
      "Column Label: u10.5, Numerical Index: 258\n",
      "Column Label: u10.6, Numerical Index: 259\n",
      "Column Label: u10.7, Numerical Index: 260\n",
      "Column Label: u10.8, Numerical Index: 261\n",
      "Column Label: u10.9, Numerical Index: 262\n",
      "Column Label: u10.10, Numerical Index: 263\n",
      "Column Label: u10.11, Numerical Index: 264\n",
      "Column Label: u10.12, Numerical Index: 265\n",
      "Column Label: u10.13, Numerical Index: 266\n",
      "Column Label: u10.14, Numerical Index: 267\n",
      "Column Label: u10.15, Numerical Index: 268\n",
      "Column Label: u10.16, Numerical Index: 269\n",
      "Column Label: u10.17, Numerical Index: 270\n",
      "Column Label: u10.18, Numerical Index: 271\n",
      "Column Label: u10.19, Numerical Index: 272\n",
      "Column Label: u10.20, Numerical Index: 273\n",
      "Column Label: u10.21, Numerical Index: 274\n",
      "Column Label: u10.22, Numerical Index: 275\n",
      "Column Label: u10.23, Numerical Index: 276\n",
      "Column Label: u10.24, Numerical Index: 277\n",
      "Column Label: u10.25, Numerical Index: 278\n",
      "Column Label: v10.1, Numerical Index: 279\n",
      "Column Label: v10.2, Numerical Index: 280\n",
      "Column Label: v10.3, Numerical Index: 281\n",
      "Column Label: v10.4, Numerical Index: 282\n",
      "Column Label: v10.5, Numerical Index: 283\n",
      "Column Label: v10.6, Numerical Index: 284\n",
      "Column Label: v10.7, Numerical Index: 285\n",
      "Column Label: v10.8, Numerical Index: 286\n",
      "Column Label: v10.9, Numerical Index: 287\n",
      "Column Label: v10.10, Numerical Index: 288\n",
      "Column Label: v10.11, Numerical Index: 289\n",
      "Column Label: v10.12, Numerical Index: 290\n",
      "Column Label: v10.13, Numerical Index: 291\n",
      "Column Label: v10.14, Numerical Index: 292\n",
      "Column Label: v10.15, Numerical Index: 293\n",
      "Column Label: v10.16, Numerical Index: 294\n",
      "Column Label: v10.17, Numerical Index: 295\n",
      "Column Label: v10.18, Numerical Index: 296\n",
      "Column Label: v10.19, Numerical Index: 297\n",
      "Column Label: v10.20, Numerical Index: 298\n",
      "Column Label: v10.21, Numerical Index: 299\n",
      "Column Label: v10.22, Numerical Index: 300\n",
      "Column Label: v10.23, Numerical Index: 301\n",
      "Column Label: v10.24, Numerical Index: 302\n",
      "Column Label: v10.25, Numerical Index: 303\n",
      "Column Label: t2m.1, Numerical Index: 304\n",
      "Column Label: t2m.2, Numerical Index: 305\n",
      "Column Label: t2m.3, Numerical Index: 306\n",
      "Column Label: t2m.4, Numerical Index: 307\n",
      "Column Label: t2m.5, Numerical Index: 308\n",
      "Column Label: t2m.6, Numerical Index: 309\n",
      "Column Label: t2m.7, Numerical Index: 310\n",
      "Column Label: t2m.8, Numerical Index: 311\n",
      "Column Label: t2m.9, Numerical Index: 312\n",
      "Column Label: t2m.10, Numerical Index: 313\n",
      "Column Label: t2m.11, Numerical Index: 314\n",
      "Column Label: t2m.12, Numerical Index: 315\n",
      "Column Label: t2m.13, Numerical Index: 316\n",
      "Column Label: t2m.14, Numerical Index: 317\n",
      "Column Label: t2m.15, Numerical Index: 318\n",
      "Column Label: t2m.16, Numerical Index: 319\n",
      "Column Label: t2m.17, Numerical Index: 320\n",
      "Column Label: t2m.18, Numerical Index: 321\n",
      "Column Label: t2m.19, Numerical Index: 322\n",
      "Column Label: t2m.20, Numerical Index: 323\n",
      "Column Label: t2m.21, Numerical Index: 324\n",
      "Column Label: t2m.22, Numerical Index: 325\n",
      "Column Label: t2m.23, Numerical Index: 326\n",
      "Column Label: t2m.24, Numerical Index: 327\n",
      "Column Label: t2m.25, Numerical Index: 328\n",
      "Column Label: stl2.1, Numerical Index: 329\n",
      "Column Label: stl2.2, Numerical Index: 330\n",
      "Column Label: stl2.3, Numerical Index: 331\n",
      "Column Label: stl2.4, Numerical Index: 332\n",
      "Column Label: stl2.5, Numerical Index: 333\n",
      "Column Label: stl2.6, Numerical Index: 334\n",
      "Column Label: stl2.7, Numerical Index: 335\n",
      "Column Label: stl2.8, Numerical Index: 336\n",
      "Column Label: stl2.9, Numerical Index: 337\n",
      "Column Label: stl2.10, Numerical Index: 338\n",
      "Column Label: stl2.11, Numerical Index: 339\n",
      "Column Label: stl2.12, Numerical Index: 340\n",
      "Column Label: stl2.13, Numerical Index: 341\n",
      "Column Label: stl2.14, Numerical Index: 342\n",
      "Column Label: stl2.15, Numerical Index: 343\n",
      "Column Label: stl2.16, Numerical Index: 344\n",
      "Column Label: stl2.17, Numerical Index: 345\n",
      "Column Label: stl2.18, Numerical Index: 346\n",
      "Column Label: stl2.19, Numerical Index: 347\n",
      "Column Label: stl2.20, Numerical Index: 348\n",
      "Column Label: stl2.21, Numerical Index: 349\n",
      "Column Label: stl2.22, Numerical Index: 350\n",
      "Column Label: stl2.23, Numerical Index: 351\n",
      "Column Label: stl2.24, Numerical Index: 352\n",
      "Column Label: stl2.25, Numerical Index: 353\n",
      "Column Label: stl3.1, Numerical Index: 354\n",
      "Column Label: stl3.2, Numerical Index: 355\n",
      "Column Label: stl3.3, Numerical Index: 356\n",
      "Column Label: stl3.4, Numerical Index: 357\n",
      "Column Label: stl3.5, Numerical Index: 358\n",
      "Column Label: stl3.6, Numerical Index: 359\n",
      "Column Label: stl3.7, Numerical Index: 360\n",
      "Column Label: stl3.8, Numerical Index: 361\n",
      "Column Label: stl3.9, Numerical Index: 362\n",
      "Column Label: stl3.10, Numerical Index: 363\n",
      "Column Label: stl3.11, Numerical Index: 364\n",
      "Column Label: stl3.12, Numerical Index: 365\n",
      "Column Label: stl3.13, Numerical Index: 366\n",
      "Column Label: stl3.14, Numerical Index: 367\n",
      "Column Label: stl3.15, Numerical Index: 368\n",
      "Column Label: stl3.16, Numerical Index: 369\n",
      "Column Label: stl3.17, Numerical Index: 370\n",
      "Column Label: stl3.18, Numerical Index: 371\n",
      "Column Label: stl3.19, Numerical Index: 372\n",
      "Column Label: stl3.20, Numerical Index: 373\n",
      "Column Label: stl3.21, Numerical Index: 374\n",
      "Column Label: stl3.22, Numerical Index: 375\n",
      "Column Label: stl3.23, Numerical Index: 376\n",
      "Column Label: stl3.24, Numerical Index: 377\n",
      "Column Label: stl3.25, Numerical Index: 378\n",
      "Column Label: iews.1, Numerical Index: 379\n",
      "Column Label: iews.2, Numerical Index: 380\n",
      "Column Label: iews.3, Numerical Index: 381\n",
      "Column Label: iews.4, Numerical Index: 382\n",
      "Column Label: iews.5, Numerical Index: 383\n",
      "Column Label: iews.6, Numerical Index: 384\n",
      "Column Label: iews.7, Numerical Index: 385\n",
      "Column Label: iews.8, Numerical Index: 386\n",
      "Column Label: iews.9, Numerical Index: 387\n",
      "Column Label: iews.10, Numerical Index: 388\n",
      "Column Label: iews.11, Numerical Index: 389\n",
      "Column Label: iews.12, Numerical Index: 390\n",
      "Column Label: iews.13, Numerical Index: 391\n",
      "Column Label: iews.14, Numerical Index: 392\n",
      "Column Label: iews.15, Numerical Index: 393\n",
      "Column Label: iews.16, Numerical Index: 394\n",
      "Column Label: iews.17, Numerical Index: 395\n",
      "Column Label: iews.18, Numerical Index: 396\n",
      "Column Label: iews.19, Numerical Index: 397\n",
      "Column Label: iews.20, Numerical Index: 398\n",
      "Column Label: iews.21, Numerical Index: 399\n",
      "Column Label: iews.22, Numerical Index: 400\n",
      "Column Label: iews.23, Numerical Index: 401\n",
      "Column Label: iews.24, Numerical Index: 402\n",
      "Column Label: iews.25, Numerical Index: 403\n",
      "Column Label: inss.1, Numerical Index: 404\n",
      "Column Label: inss.2, Numerical Index: 405\n",
      "Column Label: inss.3, Numerical Index: 406\n",
      "Column Label: inss.4, Numerical Index: 407\n",
      "Column Label: inss.5, Numerical Index: 408\n",
      "Column Label: inss.6, Numerical Index: 409\n",
      "Column Label: inss.7, Numerical Index: 410\n",
      "Column Label: inss.8, Numerical Index: 411\n",
      "Column Label: inss.9, Numerical Index: 412\n",
      "Column Label: inss.10, Numerical Index: 413\n",
      "Column Label: inss.11, Numerical Index: 414\n",
      "Column Label: inss.12, Numerical Index: 415\n",
      "Column Label: inss.13, Numerical Index: 416\n",
      "Column Label: inss.14, Numerical Index: 417\n",
      "Column Label: inss.15, Numerical Index: 418\n",
      "Column Label: inss.16, Numerical Index: 419\n",
      "Column Label: inss.17, Numerical Index: 420\n",
      "Column Label: inss.18, Numerical Index: 421\n",
      "Column Label: inss.19, Numerical Index: 422\n",
      "Column Label: inss.20, Numerical Index: 423\n",
      "Column Label: inss.21, Numerical Index: 424\n",
      "Column Label: inss.22, Numerical Index: 425\n",
      "Column Label: inss.23, Numerical Index: 426\n",
      "Column Label: inss.24, Numerical Index: 427\n",
      "Column Label: inss.25, Numerical Index: 428\n",
      "Column Label: stl4.1, Numerical Index: 429\n",
      "Column Label: stl4.2, Numerical Index: 430\n",
      "Column Label: stl4.3, Numerical Index: 431\n",
      "Column Label: stl4.4, Numerical Index: 432\n",
      "Column Label: stl4.5, Numerical Index: 433\n",
      "Column Label: stl4.6, Numerical Index: 434\n",
      "Column Label: stl4.7, Numerical Index: 435\n",
      "Column Label: stl4.8, Numerical Index: 436\n",
      "Column Label: stl4.9, Numerical Index: 437\n",
      "Column Label: stl4.10, Numerical Index: 438\n",
      "Column Label: stl4.11, Numerical Index: 439\n",
      "Column Label: stl4.12, Numerical Index: 440\n",
      "Column Label: stl4.13, Numerical Index: 441\n",
      "Column Label: stl4.14, Numerical Index: 442\n",
      "Column Label: stl4.15, Numerical Index: 443\n",
      "Column Label: stl4.16, Numerical Index: 444\n",
      "Column Label: stl4.17, Numerical Index: 445\n",
      "Column Label: stl4.18, Numerical Index: 446\n",
      "Column Label: stl4.19, Numerical Index: 447\n",
      "Column Label: stl4.20, Numerical Index: 448\n",
      "Column Label: stl4.21, Numerical Index: 449\n",
      "Column Label: stl4.22, Numerical Index: 450\n",
      "Column Label: stl4.23, Numerical Index: 451\n",
      "Column Label: stl4.24, Numerical Index: 452\n",
      "Column Label: stl4.25, Numerical Index: 453\n",
      "Column Label: fsr.1, Numerical Index: 454\n",
      "Column Label: fsr.2, Numerical Index: 455\n",
      "Column Label: fsr.3, Numerical Index: 456\n",
      "Column Label: fsr.4, Numerical Index: 457\n",
      "Column Label: fsr.5, Numerical Index: 458\n",
      "Column Label: fsr.6, Numerical Index: 459\n",
      "Column Label: fsr.7, Numerical Index: 460\n",
      "Column Label: fsr.8, Numerical Index: 461\n",
      "Column Label: fsr.9, Numerical Index: 462\n",
      "Column Label: fsr.10, Numerical Index: 463\n",
      "Column Label: fsr.11, Numerical Index: 464\n",
      "Column Label: fsr.12, Numerical Index: 465\n",
      "Column Label: fsr.13, Numerical Index: 466\n",
      "Column Label: fsr.14, Numerical Index: 467\n",
      "Column Label: fsr.15, Numerical Index: 468\n",
      "Column Label: fsr.16, Numerical Index: 469\n",
      "Column Label: fsr.17, Numerical Index: 470\n",
      "Column Label: fsr.18, Numerical Index: 471\n",
      "Column Label: fsr.19, Numerical Index: 472\n",
      "Column Label: fsr.20, Numerical Index: 473\n",
      "Column Label: fsr.21, Numerical Index: 474\n",
      "Column Label: fsr.22, Numerical Index: 475\n",
      "Column Label: fsr.23, Numerical Index: 476\n",
      "Column Label: fsr.24, Numerical Index: 477\n",
      "Column Label: fsr.25, Numerical Index: 478\n",
      "Column Label: flsr.1, Numerical Index: 479\n",
      "Column Label: flsr.2, Numerical Index: 480\n",
      "Column Label: flsr.3, Numerical Index: 481\n",
      "Column Label: flsr.4, Numerical Index: 482\n",
      "Column Label: flsr.5, Numerical Index: 483\n",
      "Column Label: flsr.6, Numerical Index: 484\n",
      "Column Label: flsr.7, Numerical Index: 485\n",
      "Column Label: flsr.8, Numerical Index: 486\n",
      "Column Label: flsr.9, Numerical Index: 487\n",
      "Column Label: flsr.10, Numerical Index: 488\n",
      "Column Label: flsr.11, Numerical Index: 489\n",
      "Column Label: flsr.12, Numerical Index: 490\n",
      "Column Label: flsr.13, Numerical Index: 491\n",
      "Column Label: flsr.14, Numerical Index: 492\n",
      "Column Label: flsr.15, Numerical Index: 493\n",
      "Column Label: flsr.16, Numerical Index: 494\n",
      "Column Label: flsr.17, Numerical Index: 495\n",
      "Column Label: flsr.18, Numerical Index: 496\n",
      "Column Label: flsr.19, Numerical Index: 497\n",
      "Column Label: flsr.20, Numerical Index: 498\n",
      "Column Label: flsr.21, Numerical Index: 499\n",
      "Column Label: flsr.22, Numerical Index: 500\n",
      "Column Label: flsr.23, Numerical Index: 501\n",
      "Column Label: flsr.24, Numerical Index: 502\n",
      "Column Label: flsr.25, Numerical Index: 503\n",
      "Column Label: u100.1, Numerical Index: 504\n",
      "Column Label: u100.2, Numerical Index: 505\n",
      "Column Label: u100.3, Numerical Index: 506\n",
      "Column Label: u100.4, Numerical Index: 507\n",
      "Column Label: u100.5, Numerical Index: 508\n",
      "Column Label: u100.6, Numerical Index: 509\n",
      "Column Label: u100.7, Numerical Index: 510\n",
      "Column Label: u100.8, Numerical Index: 511\n",
      "Column Label: u100.9, Numerical Index: 512\n",
      "Column Label: u100.10, Numerical Index: 513\n",
      "Column Label: u100.11, Numerical Index: 514\n",
      "Column Label: u100.12, Numerical Index: 515\n",
      "Column Label: u100.13, Numerical Index: 516\n",
      "Column Label: u100.14, Numerical Index: 517\n",
      "Column Label: u100.15, Numerical Index: 518\n",
      "Column Label: u100.16, Numerical Index: 519\n",
      "Column Label: u100.17, Numerical Index: 520\n",
      "Column Label: u100.18, Numerical Index: 521\n",
      "Column Label: u100.19, Numerical Index: 522\n",
      "Column Label: u100.20, Numerical Index: 523\n",
      "Column Label: u100.21, Numerical Index: 524\n",
      "Column Label: u100.22, Numerical Index: 525\n",
      "Column Label: u100.23, Numerical Index: 526\n",
      "Column Label: u100.24, Numerical Index: 527\n",
      "Column Label: u100.25, Numerical Index: 528\n",
      "Column Label: v100.1, Numerical Index: 529\n",
      "Column Label: v100.2, Numerical Index: 530\n",
      "Column Label: v100.3, Numerical Index: 531\n",
      "Column Label: v100.4, Numerical Index: 532\n",
      "Column Label: v100.5, Numerical Index: 533\n",
      "Column Label: v100.6, Numerical Index: 534\n",
      "Column Label: v100.7, Numerical Index: 535\n",
      "Column Label: v100.8, Numerical Index: 536\n",
      "Column Label: v100.9, Numerical Index: 537\n",
      "Column Label: v100.10, Numerical Index: 538\n",
      "Column Label: v100.11, Numerical Index: 539\n",
      "Column Label: v100.12, Numerical Index: 540\n",
      "Column Label: v100.13, Numerical Index: 541\n",
      "Column Label: v100.14, Numerical Index: 542\n",
      "Column Label: v100.15, Numerical Index: 543\n",
      "Column Label: v100.16, Numerical Index: 544\n",
      "Column Label: v100.17, Numerical Index: 545\n",
      "Column Label: v100.18, Numerical Index: 546\n",
      "Column Label: v100.19, Numerical Index: 547\n",
      "Column Label: v100.20, Numerical Index: 548\n",
      "Column Label: v100.21, Numerical Index: 549\n",
      "Column Label: v100.22, Numerical Index: 550\n",
      "Column Label: v100.23, Numerical Index: 551\n",
      "Column Label: v100.24, Numerical Index: 552\n",
      "Column Label: v100.25, Numerical Index: 553\n",
      "Column Label: wind_speed1, Numerical Index: 554\n",
      "Column Label: wind_speed2, Numerical Index: 555\n",
      "Column Label: wind_speed3, Numerical Index: 556\n",
      "Column Label: wind_speed4, Numerical Index: 557\n",
      "Column Label: wind_speed5, Numerical Index: 558\n",
      "Column Label: wind_speed6, Numerical Index: 559\n",
      "Column Label: wind_speed7, Numerical Index: 560\n",
      "Column Label: wind_speed8, Numerical Index: 561\n",
      "Column Label: wind_speed9, Numerical Index: 562\n",
      "Column Label: wind_speed10, Numerical Index: 563\n",
      "Column Label: wind_speed11, Numerical Index: 564\n",
      "Column Label: wind_speed12, Numerical Index: 565\n",
      "Column Label: wind_speed13, Numerical Index: 566\n",
      "Column Label: wind_speed14, Numerical Index: 567\n",
      "Column Label: wind_speed15, Numerical Index: 568\n",
      "Column Label: wind_speed16, Numerical Index: 569\n",
      "Column Label: wind_speed17, Numerical Index: 570\n",
      "Column Label: wind_speed18, Numerical Index: 571\n",
      "Column Label: wind_speed19, Numerical Index: 572\n",
      "Column Label: wind_speed20, Numerical Index: 573\n",
      "Column Label: wind_speed21, Numerical Index: 574\n",
      "Column Label: wind_speed22, Numerical Index: 575\n",
      "Column Label: wind_speed23, Numerical Index: 576\n",
      "Column Label: wind_speed24, Numerical Index: 577\n",
      "Column Label: wind_speed25, Numerical Index: 578\n"
     ]
    }
   ],
   "source": [
    "column_indices = X.columns\n",
    "numerical_indices = range(len(X.columns))\n",
    "for numerical_index, column_label in enumerate(X.columns):\n",
    "    print(f\"Column Label: {column_label}, Numerical Index: {numerical_index}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d688035-6429-491e-9bad-7b669ee1f5e3",
   "metadata": {},
   "source": [
    "explicar aqui que filtramos el dataset original con las features que nos ha dado la pipeline. Destacas que las seleccionadas son: \n",
    "- p59.162: Vertical integral of divergence of kinetic energy\n",
    "- u10n: Neutral wind at 10 m u-component\n",
    "- v10n: Neutral wind at 10 m v-component\n",
    "- u10: 10 metre U wind component\n",
    "-• v10: 10 metre V wind componen\n",
    "- iews: Instantaneous eastward turbulent surface stress\n",
    "- inss: Instantaneous northward turbulent surface\n",
    "- flsr: Forecast logarithm of surface roughness for heat\n",
    "- u100: 100 metre U wind component\n",
    "-  v100: 100 metre V wind componen\n",
    "- wind_speed:  modulus of u100 and v100tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "428aefc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['p59.162.1', 'p59.162.2', 'p59.162.3', 'p59.162.4', 'p59.162.5',\n",
       "       'p59.162.6', 'p59.162.7', 'p59.162.9', 'p59.162.11', 'p59.162.12',\n",
       "       ...\n",
       "       'wind_speed16', 'wind_speed17', 'wind_speed18', 'wind_speed19',\n",
       "       'wind_speed20', 'wind_speed21', 'wind_speed22', 'wind_speed23',\n",
       "       'wind_speed24', 'wind_speed25'],\n",
       "      dtype='object', length=250)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only the selected features in your original data X\n",
    "X_selected_features = X.iloc[:, selected_feature_indices]\n",
    "X_test = X_test.iloc[:, selected_feature_indices]\n",
    "X_selected_features.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864a71ae-a68f-431a-a595-9ec0cc508635",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "772ca61a",
   "metadata": {},
   "source": [
    "### 3.2. Imputation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7081fa1-401b-41f2-9512-307a79aceefb",
   "metadata": {},
   "source": [
    "Does imputation improve performance in this problem? Which method seem to work best?\n",
    "\n",
    "Intentamos primero elegir tipos de simple imputer, y luego ver si el iterative baja el MAE más."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d6f768-a7e8-4615-a68d-f348f5d571c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "931d07ff-220d-4df9-aee7-63428beeda6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model MAE: 318.47093175614197\n"
     ]
    }
   ],
   "source": [
    "random_state= 100516919\n",
    "\n",
    "# Load a sample dataset for demonstration\n",
    "X = X_selected_features\n",
    "y = y_train\n",
    "\n",
    "# Define the holdout split\n",
    "indices = ([-1] * len(X_train_train)) + ([0] * len(X_train_validation))\n",
    "inner = PredefinedSplit(indices)\n",
    "\n",
    "# Create a new pipeline with imputation after feature selection\n",
    "pipeline_simple_imputer = Pipeline([\n",
    "    ('imputer', SimpleImputer()), \n",
    "    ('scaler', StandardScaler()),  # Placeholder, will be replaced during grid search\n",
    "    ('knn', KNeighborsRegressor(n_jobs=-1))\n",
    "])\n",
    "\n",
    "# Define the hyperparameter grid for GridSearchCV\n",
    "param_grid_si = {\n",
    "    'imputer__strategy': ['mean', 'median', 'most_frequent']\n",
    "}\n",
    "\n",
    "# Use GridSearchCV to find the best combination of parameters\n",
    "grid_search = GridSearchCV(pipeline_simple_imputer, param_grid_si, cv=inner, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Get the best model from the grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate and print the Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Best Model MAE: {mae}\")\n",
    "\n",
    "current_step = 'SimpleImputer'\n",
    "current_mae = mae \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eca95b53-951c-49e6-859e-a26e0fcc8f81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 16\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Create a new pipeline with imputation after feature selection\u001b[39;00m\n\u001b[1;32m     10\u001b[0m pipeline_iterative_imputer \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[1;32m     11\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimputer\u001b[39m\u001b[38;5;124m'\u001b[39m, IterativeImputer()), \n\u001b[1;32m     12\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaler\u001b[39m\u001b[38;5;124m'\u001b[39m, StandardScaler()),  \u001b[38;5;66;03m# Placeholder, will be replaced during grid search\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mknn\u001b[39m\u001b[38;5;124m'\u001b[39m, KNeighborsRegressor(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     14\u001b[0m ])\n\u001b[0;32m---> 16\u001b[0m \u001b[43mpipeline_iterative_imputer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Make predictions on the test set\u001b[39;00m\n\u001b[1;32m     19\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m pipeline_iterative_imputer\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearning/lib/python3.8/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearning/lib/python3.8/site-packages/sklearn/pipeline.py:416\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model.\u001b[39;00m\n\u001b[1;32m    391\u001b[0m \n\u001b[1;32m    392\u001b[0m \u001b[38;5;124;03mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;124;03m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    415\u001b[0m fit_params_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_fit_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m--> 416\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearning/lib/python3.8/site-packages/sklearn/pipeline.py:370\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    368\u001b[0m     cloned_transformer \u001b[38;5;241m=\u001b[39m clone(transformer)\n\u001b[1;32m    369\u001b[0m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[0;32m--> 370\u001b[0m X, fitted_transformer \u001b[38;5;241m=\u001b[39m \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPipeline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_steps\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[step_idx] \u001b[38;5;241m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearning/lib/python3.8/site-packages/joblib/memory.py:353\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearning/lib/python3.8/site-packages/sklearn/pipeline.py:950\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m    949\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 950\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    951\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    952\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearning/lib/python3.8/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearning/lib/python3.8/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearning/lib/python3.8/site-packages/sklearn/impute/_iterative.py:761\u001b[0m, in \u001b[0;36mIterativeImputer.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m feat_idx \u001b[38;5;129;01min\u001b[39;00m ordered_idx:\n\u001b[1;32m    758\u001b[0m     neighbor_feat_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_neighbor_feat_idx(\n\u001b[1;32m    759\u001b[0m         n_features, feat_idx, abs_corr_mat\n\u001b[1;32m    760\u001b[0m     )\n\u001b[0;32m--> 761\u001b[0m     Xt, estimator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_impute_one_feature\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    762\u001b[0m \u001b[43m        \u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    763\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask_missing_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    764\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeat_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    765\u001b[0m \u001b[43m        \u001b[49m\u001b[43mneighbor_feat_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    766\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    767\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    769\u001b[0m     estimator_triplet \u001b[38;5;241m=\u001b[39m _ImputerTriplet(\n\u001b[1;32m    770\u001b[0m         feat_idx, neighbor_feat_idx, estimator\n\u001b[1;32m    771\u001b[0m     )\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimputation_sequence_\u001b[38;5;241m.\u001b[39mappend(estimator_triplet)\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearning/lib/python3.8/site-packages/sklearn/impute/_iterative.py:408\u001b[0m, in \u001b[0;36mIterativeImputer._impute_one_feature\u001b[0;34m(self, X_filled, mask_missing_values, feat_idx, neighbor_feat_idx, estimator, fit_mode)\u001b[0m\n\u001b[1;32m    398\u001b[0m     X_train \u001b[38;5;241m=\u001b[39m _safe_indexing(\n\u001b[1;32m    399\u001b[0m         _safe_indexing(X_filled, neighbor_feat_idx, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m    400\u001b[0m         \u001b[38;5;241m~\u001b[39mmissing_row_mask,\n\u001b[1;32m    401\u001b[0m         axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m    402\u001b[0m     )\n\u001b[1;32m    403\u001b[0m     y_train \u001b[38;5;241m=\u001b[39m _safe_indexing(\n\u001b[1;32m    404\u001b[0m         _safe_indexing(X_filled, feat_idx, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;241m~\u001b[39mmissing_row_mask,\n\u001b[1;32m    406\u001b[0m         axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m    407\u001b[0m     )\n\u001b[0;32m--> 408\u001b[0m     \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;66;03m# if no missing values, don't predict\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39msum(missing_row_mask) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearning/lib/python3.8/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearning/lib/python3.8/site-packages/sklearn/linear_model/_bayes.py:337\u001b[0m, in \u001b[0;36mBayesianRidge.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    334\u001b[0m coef_old_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    336\u001b[0m XT_y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(X\u001b[38;5;241m.\u001b[39mT, y)\n\u001b[0;32m--> 337\u001b[0m U, S, Vh \u001b[38;5;241m=\u001b[39m \u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msvd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_matrices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m eigen_vals_ \u001b[38;5;241m=\u001b[39m S\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;66;03m# Convergence loop of the bayesian ridge regression\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/MachineLearning/lib/python3.8/site-packages/scipy/linalg/_decomp_svd.py:127\u001b[0m, in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv, overwrite_a, check_finite, lapack_driver)\u001b[0m\n\u001b[1;32m    123\u001b[0m lwork \u001b[38;5;241m=\u001b[39m _compute_lwork(gesXd_lwork, a1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], a1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m    124\u001b[0m                        compute_uv\u001b[38;5;241m=\u001b[39mcompute_uv, full_matrices\u001b[38;5;241m=\u001b[39mfull_matrices)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# perform decomposition\u001b[39;00m\n\u001b[0;32m--> 127\u001b[0m u, s, v, info \u001b[38;5;241m=\u001b[39m \u001b[43mgesXd\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_uv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_uv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlwork\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlwork\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mfull_matrices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_matrices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite_a\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_a\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSVD did not converge\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load a sample dataset for demonstration\n",
    "X = X_selected_features\n",
    "y = y_train\n",
    "\n",
    "# Define the holdout split\n",
    "indices = ([-1] * len(X_train_train)) + ([0] * len(X_train_validation))\n",
    "inner = PredefinedSplit(indices)\n",
    "\n",
    "# Create a new pipeline with imputation after feature selection\n",
    "pipeline_iterative_imputer = Pipeline([\n",
    "    ('imputer', IterativeImputer()), \n",
    "    ('scaler', StandardScaler()),  # Placeholder, will be replaced during grid search\n",
    "    ('knn', KNeighborsRegressor(n_jobs=-1))\n",
    "])\n",
    "\n",
    "pipeline_iterative_imputer.fit(X, y)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = pipeline_iterative_imputer.predict(X_test)\n",
    "\n",
    "# Calculate and print the Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Iterative imputer MAE: {mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da46695f-d49a-4be9-b61b-623b48da0f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a sample dataset for demonstration\n",
    "X = X_selected_features\n",
    "y = y_train\n",
    "\n",
    "# Define the holdout split\n",
    "indices = ([-1] * len(X_train_train)) + ([0] * len(X_train_validation))\n",
    "inner = PredefinedSplit(indices)\n",
    "\n",
    "# Create a new pipeline with imputation after feature selection\n",
    "pipeline_KNN_imputer = Pipeline([\n",
    "    ('imputer', KNNImputer()), \n",
    "    ('scaler', StandardScaler()),  \n",
    "    ('knn', KNeighborsRegressor(n_jobs=-1))\n",
    "])\n",
    "\n",
    "pipeline_KNN_imputer.fit(X, y)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = pipeline_KNN_imputer.predict(X_test)\n",
    "\n",
    "# Calculate and print the Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"KNN imputer MAE: {mae}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a98b43-5761-4339-bb23-bbd5b5dbe89e",
   "metadata": {},
   "source": [
    "Como el MAE es menor para el iterative, usamos este para transformar nuestros datos y continuar al último paso del preprocesado, el scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6ed6e8-d7dc-40b7-b59e-221868bf9af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the imputed data\n",
    "X_imputed = pipeline_iterative_imputer.named_steps['imputer'].transform(X)\n",
    "X_imputed \n",
    "X_test = pipeline_iterative_imputer.named_steps['imputer'].transform(X_test)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6864c55e",
   "metadata": {},
   "source": [
    "### 3.3. Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0e85c8-1bc4-4a5b-bfd1-d76c1ea30805",
   "metadata": {},
   "source": [
    "Por último, ahora que ya tenemos las mejores features seleccionadas y habiendo imputado con el iterative, hay que ver qué método de escalado es mejor (esto luego solo afecta a los métodos que calculan distancias como el knn pero se aplicará al dataset para todos los casos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1411155a-f1d3-4acc-8e06-0408e3bf3706",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_imputed\n",
    "y = y_train\n",
    "\n",
    "# Define the holdout split\n",
    "indices = ([-1] * len(X_train_train)) + ([0] * len(X_train_validation))\n",
    "inner = PredefinedSplit(indices)\n",
    "\n",
    "# Create a new pipeline with scaling after feature selection and imputation\n",
    "pipeline_standard_scaler = Pipeline([\n",
    "    ('scaler', StandardScaler()), \n",
    "    ('knn', KNeighborsRegressor(n_jobs=-1))\n",
    "])\n",
    "\n",
    "pipeline_standard_scaler.fit(X, y)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = pipeline_standard_scaler.predict(X_test)\n",
    "\n",
    "# Calculate and print the Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Standard scaler MAE: {mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e619e178-1500-4aab-95b9-6566844f361e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new pipeline with scaling after feature selection and imputation\n",
    "pipeline_minmax_scaler = Pipeline([\n",
    "    ('scaler', MinMaxScaler()), \n",
    "    ('knn', KNeighborsRegressor(n_jobs=-1))\n",
    "])\n",
    "\n",
    "pipeline_minmax_scaler.fit(X, y)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = pipeline_minmax_scaler.predict(X_test)\n",
    "\n",
    "# Calculate and print the Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"MinMax scaler MAE: {mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5b926f-b0f8-4281-aad7-61fafa4a108e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new pipeline with scaling after feature selection and imputation\n",
    "pipeline_robust_scaler = Pipeline([\n",
    "    ('scaler', RobustScaler()), \n",
    "    ('knn', KNeighborsRegressor(n_jobs=-1))\n",
    "])\n",
    "\n",
    "pipeline_robust_scaler.fit(X, y)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = pipeline_robust_scaler.predict(X_test)\n",
    "\n",
    "# Calculate and print the Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Robust scaler MAE: {mae}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc41d214-1a0f-48ec-8412-449e4b91b3cd",
   "metadata": {},
   "source": [
    "### 3.4. Final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d647db-cd51-45ef-adf6-4c23e81ef517",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pipeline_robust_scaler.named_steps['scaler'].transform(X)\n",
    "X_train\n",
    "X_test = pipeline_robust_scaler.named_steps['scaler'].transform(X_test)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "999f7f1f-98d3-4398-a083-8284a60f32b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X_train and X_test are NumPy arrays\n",
    "#np.savetxt('X_train.csv', X_train, delimiter=';')\n",
    "#np.savetxt('X_test.csv', X_test, delimiter=';')\n",
    "#np.savetxt('X_train_train.csv', X_train_train, delimiter=';')\n",
    "#np.savetxt('X_train_validation.csv', X_train_validation, delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d49ed8a-0951-4c12-8074-f704c5d2178b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.31177367, -0.31696642, -0.31655972, ..., -0.23377745,\n",
       "        -0.21241713, -0.19716302],\n",
       "       [-0.09378879, -0.10216953, -0.10638298, ...,  0.11043825,\n",
       "         0.10968315,  0.1042859 ],\n",
       "       [ 0.05649893,  0.04862603,  0.04390409, ...,  0.70883047,\n",
       "         0.67642773,  0.64116408],\n",
       "       ...,\n",
       "       [ 0.54200045,  0.58215538,  0.62177319, ..., -0.2946182 ,\n",
       "        -0.25202736, -0.21299333],\n",
       "       [ 0.09334912,  0.09679973,  0.10300574, ...,  0.88391007,\n",
       "         0.86213978,  0.84281453],\n",
       "       [ 0.06947422,  0.07564338,  0.08476866, ...,  0.47437584,\n",
       "         0.52065433,  0.57001822]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.loadtxt('X_train.csv', delimiter=';')\n",
    "X_test = np.loadtxt('X_test.csv', delimiter=';')\n",
    "X_train_train = np.loadtxt('X_train_train.csv', delimiter=';')\n",
    "X_train_validation = np.loadtxt('X_train_validation.csv', delimiter=';')\n",
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787a8dc9-79fd-4fcf-9665-a3e7bdf02848",
   "metadata": {},
   "source": [
    "## 4. Modeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a96cbd-719c-4c41-93b1-ec42b379972a",
   "metadata": {},
   "source": [
    "### 4.1. Dummy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03985d5-0a23-4ec8-94e4-6008013af6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to store results\n",
    "results_df = pd.DataFrame(columns=['Model', 'MAE', 'Training Time'])\n",
    "\n",
    "# Function to add results to the DataFrame\n",
    "def add_result(model_name, mae, training_time):\n",
    "    results_df.loc[len(results_df)] = [model_name, mae, training_time]\n",
    "\n",
    "indices = ([-1] * len(X_train_train)) + ([0] * len(X_train_validation))\n",
    "inner = PredefinedSplit(indices)\n",
    "\n",
    "dummy_reg =DummyRegressor(strategy='median')\n",
    "\n",
    "# Measure training time\n",
    "start_time = time.time()\n",
    "\n",
    "# Fit the model and calculate scores\n",
    "dummy_scores = cross_val_score(dummy_reg, X_train, y_train, cv=inner, scoring='neg_mean_absolute_error')\n",
    "\n",
    "# Measure end time\n",
    "end_time = time.time()\n",
    "\n",
    "training_time= end_time-start_time\n",
    "\n",
    "# Add results to the DataFrame\n",
    "add_result('Dummy Mean', -dummy_scores.mean(), training_time)\n",
    "\n",
    "# Print the results DataFrame\n",
    "results_df\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774d1b5d-0cd2-4ed4-a915-eebc7075ae92",
   "metadata": {},
   "source": [
    "### 4.2. Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9857b2-6ef6-4d19-a6f6-5bc5ce7fad06",
   "metadata": {},
   "source": [
    "#### 4.2.1 Default hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4599381-35d4-4b3b-bf13-a10009059926",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_reg = DecisionTreeRegressor(random_state=random_state)\n",
    "\n",
    "# Measure training time\n",
    "start_time = time.time()\n",
    "\n",
    "tree_default_scores = cross_val_score(tree_reg,  X_train, y_train, cv=inner, scoring='neg_mean_absolute_error')\n",
    "\n",
    "# Measure end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate training time\n",
    "training_time = end_time - start_time\n",
    "\n",
    "add_result('Tree Default', -tree_default_scores.mean(), training_time)\n",
    "\n",
    "results_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981c1092-3c74-4e20-affb-fbe8daed6bc2",
   "metadata": {},
   "source": [
    "#### 4.2.2. HPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d499a1e1-59da-492f-8c08-a76b6c3e5301",
   "metadata": {},
   "source": [
    "Decision trees hyperparameters:\n",
    "- max_depth: the maximum depth of the tree\n",
    "- \tmin_samples_split: the minimum number of instances to splits a node (the default value is 2: if a node contains fewer  than instances, the node is not split)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e59c22c-bced-454c-b1f1-f18e71ad5abd",
   "metadata": {},
   "source": [
    "##### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe039ba-0c86-451b-8e0c-74c36590a67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = ([-1] * len(X_train_train)) + ([0] * len(X_train_validation))\n",
    "inner = PredefinedSplit(indices)\n",
    "\n",
    "param_random_tree = {'max_depth': [2,4,6,8,10,12,14,16,18,20],\n",
    "                     'min_samples_split': [100,110,120,130]}\n",
    "\n",
    "random_search_tree = RandomizedSearchCV(tree_reg, param_random_tree, cv= inner, scoring='neg_mean_absolute_error', random_state= random_state) \n",
    "\n",
    "# Measure training time\n",
    "start_time = time.time()\n",
    "\n",
    "random_search_tree.fit(X_train, y_train)\n",
    "\n",
    "# Measure end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate training time\n",
    "training_time = end_time - start_time\n",
    "\n",
    "#We print the selected parameters to be sure we are not on the boundaries of the search space\n",
    "\n",
    "random_search_tree.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe9d459-2a92-44be-bbd4-1f219bb19590",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_result('Tree Random HPO', -random_search_tree.best_score_, training_time)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ffa191-0640-4c94-8fe3-2cc5dafe43fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39b72f6a-617f-42bc-9e89-f4723822ca4f",
   "metadata": {},
   "source": [
    "##### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8151ea8f-43c6-43fd-b12e-15600af82b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = ([-1] * len(X_train_train)) + ([0] * len(X_train_validation))\n",
    "inner = PredefinedSplit(indices)\n",
    "\n",
    "param_grid_tree = {'max_depth': [2,4,6,8,10,12,14,16,18,20],\n",
    "                     'min_samples_split': [100,110,120,130]}\n",
    "\n",
    "grid_search_tree = GridSearchCV(tree_reg, param_grid_tree, cv= inner, scoring='neg_mean_absolute_error') \n",
    "\n",
    "# Measure training time\n",
    "start_time = time.time()\n",
    "\n",
    "grid_search_tree.fit(X_train, y_train)\n",
    "\n",
    "# Measure end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate training time\n",
    "training_time = end_time - start_time\n",
    "\n",
    "add_result('Tree Grid HPO', -grid_search_tree.best_score_, training_time)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de871ac8-697b-4e8a-8a15-760b5bb33778",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_step = 'Tree Grid.Search'\n",
    "current_mae =  -grid_search_tree.best_score_\n",
    "\n",
    "# Add the values to the DataFrame\n",
    "mae_df = mae_df.append({'Step': current_step, 'MAE': current_mae}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e867b0-2968-4633-ac26-b9482ed66c29",
   "metadata": {},
   "source": [
    "##### Bayes optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3e2d8a-4c1b-4521-98d8-1c92c428eaec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "indices = ([-1] * len(X_train_train)) + ([0] * len(X_train_validation))\n",
    "inner = PredefinedSplit(indices)\n",
    "\n",
    "param_bayes_tree = {'max_depth': Integer(2, 20),\n",
    "                     'min_samples_split': Integer(100, 130)}\n",
    "\n",
    "budget=30 #number of iterations\n",
    "bayes_search_tree = BayesSearchCV(tree_reg, \n",
    "                                 param_bayes_tree, \n",
    "                                 cv= inner, \n",
    "                                 scoring='neg_mean_absolute_error',\n",
    "                                n_iter=budget,\n",
    "                                n_jobs=-1, verbose=1) \n",
    "\n",
    "\n",
    "# Measure training time\n",
    "start_time = time.time()\n",
    "\n",
    "bayes_search_tree.fit(X_train, y_train)\n",
    "\n",
    "# Measure end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate training time\n",
    "training_time = end_time - start_time\n",
    "\n",
    "add_result('Tree Bayes HPO', -bayes_search_tree.best_score_, training_time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0f8736-1f27-42fc-8b0a-9cc7b1062f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0169c272-d652-49e3-ba79-d2063ba39589",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_step = 'Tree Bayes.Search'\n",
    "current_mae =  -bayes_search_tree.best_score_\n",
    "\n",
    "# Add the values to the DataFrame\n",
    "mae_df = mae_df.append({'Step': current_step, 'MAE': current_mae}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6847a9a9-e9af-4b23-8b30-64566fd5a004",
   "metadata": {},
   "source": [
    "##### Halving Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5bc9b2-ad1d-4f6e-b343-ecda987e058c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "indices = ([-1] * len(X_train_train)) + ([0] * len(X_train_validation))\n",
    "inner = PredefinedSplit(indices)\n",
    "\n",
    "param_halving_tree = {'max_depth': list(range(2, 20, 1)),\n",
    "                     'min_samples_split':list(range(100, 130, 1))}\n",
    "\n",
    "halving_search_tree = HalvingGridSearchCV(tree_reg, \n",
    "                                 param_halving_tree, \n",
    "                                 cv= inner, \n",
    "                                 scoring='neg_mean_absolute_error',\n",
    "                                factor= 2, #proportion of candidates that are selected in each iteration\n",
    "                                min_resources='exhaust', #“exhaust” means that first iteration is as large as possible, so that in the last iteration, the entire training data is used.\n",
    "                                max_resources='auto',\n",
    "                                n_jobs=-1, verbose=1) \n",
    "\n",
    "\n",
    "# Measure training time\n",
    "start_time = time.time()\n",
    "\n",
    "halving_search_tree.fit(X_train, y_train)\n",
    "\n",
    "# Measure end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate training time\n",
    "training_time = end_time - start_time\n",
    "\n",
    "add_result('Tree Halving HPO', -halving_search_tree.best_score_, training_time)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4816190e-4ba0-4709-bc2e-666a39b57eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350bdccd-9c24-43cc-ad31-ebacb28dee81",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_step = 'Tree Halving.Search'\n",
    "current_mae =  -halving_search_tree.best_score_\n",
    "\n",
    "# Add the values to the DataFrame\n",
    "mae_df = mae_df.append({'Step': current_step, 'MAE': current_mae}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa090d25-4ca7-4374-957e-25cf698aeddc",
   "metadata": {},
   "source": [
    "### 4.3. KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77317e4e-b992-426e-b45e-5b2f682731a4",
   "metadata": {},
   "source": [
    "#### 4.3.1. Default hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499d4029-f1c1-44cc-a100-2eda9fcdcd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = ([-1] * len(X_train_train)) + ([0] * len(X_train_validation))\n",
    "inner = PredefinedSplit(indices)\n",
    "\n",
    "# Create a KNN regressor with default parameters\n",
    "knn_reg = KNeighborsRegressor(n_jobs=-1)\n",
    "\n",
    "# Measure training time\n",
    "start_time = time.time()\n",
    "\n",
    "# Perform cross-validation and calculate mean absolute error\n",
    "knn_scores = cross_val_score(knn_reg, X_train, y_train, cv=inner, scoring='neg_mean_absolute_error')\n",
    "\n",
    "# Measure end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate training time\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# Add the results to a dataframe or any data structure you're using to store results\n",
    "add_result('KNN Default', -knn_scores.mean(), training_time)\n",
    "\n",
    "# Assuming 'add_result' is a function that adds results to your 'results_df'\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c42f310-e902-4f90-80f3-8c2f383a151b",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_step = 'KNN default'\n",
    "current_mae =  -knn_scores.mean()\n",
    "\n",
    "# Add the values to the DataFrame\n",
    "mae_df = mae_df.append({'Step': current_step, 'MAE': current_mae}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cd906f-b2c4-4a65-99f6-cdd2f881ea41",
   "metadata": {},
   "source": [
    "#### 4.3.2. HPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745cd79b-d12b-4bf1-8efd-8fa2ff5ebebd",
   "metadata": {},
   "source": [
    "##### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad83205-a7e2-44a0-b954-05f2e538af7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid for random search\n",
    "param_dist = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],  \n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "}\n",
    "\n",
    "# Create a KNN regressor with default parameters\n",
    "knn_reg = KNeighborsRegressor()\n",
    "\n",
    "# Define the randomized search object\n",
    "random_search = RandomizedSearchCV(knn_reg, param_distributions=param_dist, scoring='neg_mean_absolute_error', cv=inner, n_jobs=-1,random_state= random_state)\n",
    "\n",
    "# Measure training time\n",
    "start_time = time.time()\n",
    "\n",
    "# Fit the randomized search to the data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Measure end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate training time\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "\n",
    "# Print the mean absolute error on the validation set\n",
    "print(\"Validation MAE:\", -random_search.best_score_)\n",
    "\n",
    "# Print training time\n",
    "print(\"Training Time:\", training_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6eafbd1-af43-4d33-8f8d-b8e0685a8ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_result('KNN Random HPO', -random_search.best_score_, training_time)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93c1634-7d90-4f82-a8b7-8fa1ab2c083f",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_step = 'KNN Random'\n",
    "current_mae =  -random_search.best_score_\n",
    "\n",
    "# Add the values to the DataFrame\n",
    "mae_df = mae_df.append({'Step': current_step, 'MAE': current_mae}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a95ad58-0729-4e52-8205-c4b25cb2bf85",
   "metadata": {},
   "source": [
    "##### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b242de-a3bd-45b2-bd90-8b88fbf7038e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid for grid search\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],  \n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "}\n",
    "\n",
    "# Create a KNN regressor with default parameters\n",
    "knn_reg = KNeighborsRegressor()\n",
    "\n",
    "# Define the grid search object\n",
    "grid_search_knn = GridSearchCV(knn_reg, param_grid=param_grid, scoring='neg_mean_absolute_error', cv=inner, n_jobs=-1)\n",
    "\n",
    "# Measure training time\n",
    "start_time = time.time()\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search_knn.fit(X_train, y_train)\n",
    "\n",
    "# Measure end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate training time\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_search_knn.best_params_)\n",
    "\n",
    "# Print the mean absolute error on the validation set\n",
    "print(\"Validation MAE:\", -grid_search_knn.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7094f6-3818-4f01-a275-6f5b6acf64e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the results to the dataframe\n",
    "add_result('KNN Grid HPO', -grid_search_knn.best_score_, training_time)\n",
    "\n",
    "# Display the results dataframe\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8f4298-de59-4b5a-aa6f-686efe1f06d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_step = 'KNN Grid'\n",
    "current_mae =  -grid_search_knn.best_score_\n",
    "\n",
    "# Add the values to the DataFrame\n",
    "mae_df = mae_df.append({'Step': current_step, 'MAE': current_mae}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6b149e-048b-4280-b3a1-46a0831477a3",
   "metadata": {},
   "source": [
    "##### Bayes optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30737d32-2f07-4b58-8122-a26574bf3a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter search space for Bayesian optimization\n",
    "param_space = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11], \n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "}\n",
    "\n",
    "# Create a KNN regressor with default parameters\n",
    "knn_reg = KNeighborsRegressor()\n",
    "\n",
    "budget=20\n",
    "# Define the Bayesian search object\n",
    "bayes_search_knn = BayesSearchCV(knn_reg, search_spaces=param_space, scoring='neg_mean_absolute_error', cv=inner, n_jobs=-1, n_iter=budget, verbose=1)\n",
    "\n",
    "# Measure training time\n",
    "start_time = time.time()\n",
    "\n",
    "# Fit the Bayesian search to the data\n",
    "bayes_search_knn.fit(X_train, y_train)\n",
    "\n",
    "# Measure end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate training time\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", bayes_search_knn.best_params_)\n",
    "\n",
    "# Print the mean absolute error on the validation set\n",
    "print(\"Validation MAE:\", -bayes_search_knn.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ac2f05-549d-4743-bed4-3515bb179f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the results to the dataframe\n",
    "add_result('KNN Bayes HPO', -bayes_search_knn.best_score_, training_time)\n",
    "\n",
    "# Display the results dataframe\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b11225-6f6e-4a17-90a9-511abc6146c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_step = 'KNN Bayes'\n",
    "current_mae =  -bayes_search_knn.best_score_\n",
    "\n",
    "# Add the values to the DataFrame\n",
    "mae_df = mae_df.append({'Step': current_step, 'MAE': current_mae}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727ae5cd-bac8-4a32-b7b3-39df313093cf",
   "metadata": {},
   "source": [
    "##### Halving Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7fc561-486e-498d-985f-8d6b0470caac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a KNeighborsRegressor instance\n",
    "knn_reg = KNeighborsRegressor()\n",
    "\n",
    "# Create a PredefinedSplit to split the data into training and validation sets\n",
    "indices = ([-1] * len(X_train_train)) + ([0] * len(X_train_validation))\n",
    "inner = PredefinedSplit(indices)\n",
    "\n",
    "# Define the parameter search space for the Halving Grid Search\n",
    "param_halving_knn = {\n",
    "    'n_neighbors': list(range(3, 12, 2)),\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "}\n",
    "\n",
    "# Create a HalvingGridSearchCV instance for KNN\n",
    "halving_search_knn = HalvingGridSearchCV(\n",
    "    knn_reg,\n",
    "    param_halving_knn,\n",
    "    cv=inner,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    factor=2,  # proportion of candidates that are selected in each iteration\n",
    "    min_resources='exhaust',  # “exhaust” means that the first iteration is as large as possible\n",
    "    max_resources='auto',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Measure training time\n",
    "start_time = time.time()\n",
    "\n",
    "halving_search_knn.fit(X_train, y_train)\n",
    "\n",
    "# Measure end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate training time\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best Parameters:\", halving_search_knn.best_params_)\n",
    "print(\"Best Score:\", -halving_search_knn.best_score_)\n",
    "print(\"Training Time:\", training_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88518cfb-75cb-4e72-a221-da1f6eb4590e",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_result('KNN Halving HPO', -halving_search_knn.best_score_, training_time)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928f4b77-cbdc-4251-a754-1bdf4556c304",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_step = 'KNN Halving'\n",
    "current_mae =  -halving_search_knn.best_score_\n",
    "\n",
    "# Add the values to the DataFrame\n",
    "mae_df = mae_df.append({'Step': current_step, 'MAE': current_mae}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767c5a5d-97b9-4228-94d5-d0d6d1adc140",
   "metadata": {},
   "source": [
    "### 4.4. Ensemble 1: Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6651bd23-c491-4f41-802a-12b24088c1a3",
   "metadata": {},
   "source": [
    "#### 4.4.1. Default hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b34dbb3-704c-40b9-b85e-873a2c242e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_for_reg = RandomForestRegressor(random_state=random_state)\n",
    "\n",
    "# Measure training time\n",
    "start_time = time.time()\n",
    "\n",
    "rand_for_default_scores = cross_val_score(rand_for_reg,  X_train, y_train, cv=inner, scoring='neg_mean_absolute_error')\n",
    "\n",
    "# Measure end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate training time\n",
    "training_time = end_time - start_time\n",
    "\n",
    "add_result('RF Default', -rand_for_default_scores.mean(), training_time)\n",
    "\n",
    "results_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71477558-f0f1-4dec-a7ae-bda98044ffd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_step = 'RF Default'\n",
    "current_mae =  -rand_for_default_scores.mean()\n",
    "\n",
    "# Add the values to the DataFrame\n",
    "mae_df = mae_df.append({'Step': current_step, 'MAE': current_mae}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec6c48f-661c-4a06-8aa4-65e50913c4c6",
   "metadata": {},
   "source": [
    "#### 4.4.2. HPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23da3aa7-6897-46a2-9be7-c418969ff306",
   "metadata": {},
   "source": [
    "Random forest Hyperparameters:\n",
    "- n_estimators: number of trees (base models) in the\n",
    "ensemble: there should be enough trees in the\n",
    "ensemble. The default (100) usually works well, but it\n",
    "can also be tuned.\n",
    "- max_features : mtry or m. Size of the random subset\n",
    "of features to be compared at every node. Possible\n",
    "values: sqrt, log2, or a number between 1 and the\n",
    "maximum number of features in the dataset. It can also be a real number between 0 and 1 (fraction of\n",
    "features)\n",
    "- max_depth / min_samples_split: hyper parameters of\n",
    "the trees (base models\n",
    "- njobs is not a hyper parameter, but allows the RF to\n",
    "be trained in parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c975b1-ab68-45b4-8e28-fdb6ffa8c783",
   "metadata": {},
   "source": [
    "##### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7962fc22-7793-4864-bc30-0233811c5e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = ([-1] * len(X_train_train)) + ([0] * len(X_train_validation))\n",
    "inner = PredefinedSplit(indices)\n",
    "\n",
    "param_random_RF = {'max_depth': [2,4,6,8,10,12,14,16,18,20],\n",
    "                     'min_samples_split': [100,110,120,130],\n",
    "                  'n_estimators':[25,50,100,150],\n",
    "                  'max_features':[0.2,0.4,0.6,0.8,1]}\n",
    "\n",
    "random_search_RF = RandomizedSearchCV(rand_for_reg, param_random_RF, cv= inner, scoring='neg_mean_absolute_error', random_state= random_state) \n",
    "\n",
    "# Measure training time\n",
    "start_time = time.time()\n",
    "\n",
    "random_search_RF.fit(X_train, y_train)\n",
    "\n",
    "# Measure end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate training time\n",
    "training_time = end_time - start_time\n",
    "\n",
    "#We print the selected parameters to be sure we are not on the boundaries of the search space\n",
    "\n",
    "random_search_RF.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b0b719-6969-4626-935a-a1b668ccf1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_result('RF Random HPO', -random_search_RF.best_score_, training_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e32b4e1-db6d-4656-86c0-962e157e0343",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e702b727-3afe-4dc5-b9d8-34318c1b3152",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_step = 'RF Random'\n",
    "current_mae =   -random_search_RF.best_score_\n",
    "\n",
    "# Add the values to the DataFrame\n",
    "mae_df = mae_df.append({'Step': current_step, 'MAE': current_mae}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73901a1f-9233-4b48-b2b3-2525214ce2f7",
   "metadata": {},
   "source": [
    "##### Halving Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227e6f03-b61e-4a5e-9e02-6059fd60bc4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "indices = ([-1] * len(X_train_train)) + ([0] * len(X_train_validation))\n",
    "inner = PredefinedSplit(indices)\n",
    "\n",
    "param_halving_RF = {'max_depth': list(range(2, 20, 2)),\n",
    "                     'min_samples_split':list(range(100, 130, 5)),\n",
    "                     'n_estimators':list(range(50,150, 50)),\n",
    "                       'max_features':[0.2,0.4,0.6,0.8,1]}\n",
    "\n",
    "\n",
    "halving_search_RF = HalvingGridSearchCV(rand_for_reg, \n",
    "                                 param_halving_RF, \n",
    "                                 cv= inner, \n",
    "                                 scoring='neg_mean_absolute_error',\n",
    "                                factor= 2, #proportion of candidates that are selected in each iteration\n",
    "                                min_resources='exhaust', #“exhaust” means that first iteration is as large as possible, so that in the last iteration, the entire training data is used.\n",
    "                                max_resources='auto',\n",
    "                                n_jobs=-1, verbose=1) \n",
    "\n",
    "\n",
    "# Measure training time\n",
    "start_time = time.time()\n",
    "\n",
    "halving_search_RF.fit(X_train, y_train)\n",
    "\n",
    "# Measure end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate training time\n",
    "training_time = end_time - start_time\n",
    "\n",
    "\n",
    "halving_search_RF.best_params_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d95c7fb-e418-428f-8233-4f9f69ebfafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_result('RF Halving HPO', -halving_search_RF.best_score_, training_time)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3366bb8-4f5a-4f35-aded-ea907cf7e80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850411b1-73ae-4a83-a51c-93a56b8e63f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_step = 'RF Halving'\n",
    "current_mae = -halving_search_RF.best_score_\n",
    "\n",
    "# Add the values to the DataFrame\n",
    "mae_df = mae_df.append({'Step': current_step, 'MAE': current_mae}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3de220-c92b-430d-9b5c-7d57aca57219",
   "metadata": {},
   "source": [
    "### 4.5. Ensemble 2: Gradient Boosting\n",
    "custom loss function for boosting!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbec1058-7402-4a50-8f08-f022da9ab735",
   "metadata": {},
   "source": [
    "#### 4.5.1. Default hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f434820-d792-4b84-8695-94ce0ae3ac57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a GradientBoostingRegressor instance with default parameters\n",
    "gb_reg = GradientBoostingRegressor(random_state=random_state)\n",
    "\n",
    "# Measure training time\n",
    "start_time = time.time()\n",
    "\n",
    "# Use cross_val_score for cross-validation\n",
    "gb_default_scores = cross_val_score(gb_reg, X_train, y_train, cv=inner, scoring='neg_mean_absolute_error')\n",
    "\n",
    "# Measure end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate training time\n",
    "training_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ef6181-6bf2-44ba-a721-8d424372549f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the results to your results dataframe or store them as needed\n",
    "add_result('GB Default', -gb_default_scores.mean(), training_time)\n",
    "\n",
    "# Display or save your results dataframe\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2175c12-f5fa-4893-9ff2-e4102102cb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_step = 'GB Default'\n",
    "current_mae = -gb_default_scores.mean()\n",
    "\n",
    "# Add the values to the DataFrame\n",
    "mae_df = mae_df.append({'Step': current_step, 'MAE': current_mae}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929bdb8f-b4bc-4dbc-904d-7c1a5cb4e89f",
   "metadata": {},
   "source": [
    "#### 4.5.2. HPO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2027fe66-f5cc-4986-97c2-45dc2d5ece74",
   "metadata": {},
   "source": [
    "##### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d2beb6-0aaf-4188-8c31-d69c40d7b0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a GradientBoostingRegressor instance\n",
    "gb_reg = GradientBoostingRegressor()\n",
    "\n",
    "# Create a PredefinedSplit to split the data into training and validation sets\n",
    "indices = ([-1] * len(X_train_train)) + ([0] * len(X_train_validation))\n",
    "inner = PredefinedSplit(indices)\n",
    "\n",
    "# Define the parameter search space for RandomizedSearchCV\n",
    "param_random_gb = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "}\n",
    "\n",
    "# Create a RandomizedSearchCV instance for Gradient Boosting\n",
    "random_search_gb = RandomizedSearchCV(\n",
    "    gb_reg,\n",
    "    param_distributions=param_random_gb,\n",
    "    cv=inner,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=random_state  # Set a random seed for reproducibility\n",
    ")\n",
    "\n",
    "# Measure training time\n",
    "start_time = time.time()\n",
    "\n",
    "random_search_gb.fit(X_train, y_train)\n",
    "\n",
    "# Measure end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate training time\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best Parameters:\", random_search_gb.best_params_)\n",
    "print(\"Best Score:\", -random_search_gb.best_score_)\n",
    "print(\"Training Time:\", training_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e070b98-d037-4091-be5c-92574d5d971d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the results to your results dataframe or store them as needed\n",
    "add_result('GB Random HPO', -random_search_gb.best_score_, training_time)\n",
    "\n",
    "# Display or save your results dataframe\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9deead-375e-45c7-b75e-bc4bed2de28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_step = 'GB Random'\n",
    "current_mae = -random_search_gb.best_score_\n",
    "\n",
    "# Add the values to the DataFrame\n",
    "mae_df = mae_df.append({'Step': current_step, 'MAE': current_mae}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2810b53-e9a8-46bc-ab33-99788d117fb4",
   "metadata": {},
   "source": [
    "##### Halving Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e23c42b-152a-4b1b-9804-1f18e4b6dc5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 7\n",
      "n_required_iterations: 7\n",
      "n_possible_iterations: 7\n",
      "min_resources_: 57\n",
      "max_resources_: 3649\n",
      "aggressive_elimination: False\n",
      "factor: 2\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 108\n",
      "n_resources: 57\n",
      "Fitting 1 folds for each of 108 candidates, totalling 108 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 54\n",
      "n_resources: 114\n",
      "Fitting 1 folds for each of 54 candidates, totalling 54 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 27\n",
      "n_resources: 228\n",
      "Fitting 1 folds for each of 27 candidates, totalling 27 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 14\n",
      "n_resources: 456\n",
      "Fitting 1 folds for each of 14 candidates, totalling 14 fits\n",
      "----------\n",
      "iter: 4\n",
      "n_candidates: 7\n",
      "n_resources: 912\n",
      "Fitting 1 folds for each of 7 candidates, totalling 7 fits\n",
      "----------\n",
      "iter: 5\n",
      "n_candidates: 4\n",
      "n_resources: 1824\n",
      "Fitting 1 folds for each of 4 candidates, totalling 4 fits\n",
      "----------\n",
      "iter: 6\n",
      "n_candidates: 2\n",
      "n_resources: 3648\n",
      "Fitting 1 folds for each of 2 candidates, totalling 2 fits\n",
      "Best Parameters: {'learning_rate': 0.1, 'max_depth': 3, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Best Score: 280.40665501329966\n",
      "Training Time: 90.1151807308197\n"
     ]
    }
   ],
   "source": [
    "# Create a GradientBoostingRegressor instance\n",
    "gb_reg = GradientBoostingRegressor()\n",
    "\n",
    "# Create a PredefinedSplit to split the data into training and validation sets\n",
    "indices = ([-1] * len(X_train_train)) + ([0] * len(X_train_validation))\n",
    "inner = PredefinedSplit(indices)\n",
    "\n",
    "# Define the parameter search space for the Halving Grid Search\n",
    "param_halving_gb = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Create a HalvingGridSearchCV instance for Gradient Boosting\n",
    "halving_search_gb = HalvingGridSearchCV(\n",
    "    gb_reg,\n",
    "    param_halving_gb,\n",
    "    cv=inner,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    factor=2,  # proportion of candidates that are selected in each iteration\n",
    "    min_resources='exhaust',  # “exhaust” means that the first iteration is as large as possible\n",
    "    max_resources='auto',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Measure training time\n",
    "start_time = time.time()\n",
    "\n",
    "halving_search_gb.fit(X_train, y_train)\n",
    "\n",
    "# Measure end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate training time\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best Parameters:\", halving_search_gb.best_params_)\n",
    "print(\"Best Score:\", -halving_search_gb.best_score_)\n",
    "print(\"Training Time:\", training_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e12ae905-0792-444f-ba88-8802a7e43a64",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'add_result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Add the results to your results dataframe or store them as needed\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43madd_result\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGB Halving HPO\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m-\u001b[39mhalving_search_gb\u001b[38;5;241m.\u001b[39mbest_score_, training_time)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Display or save your results dataframe\u001b[39;00m\n\u001b[1;32m      5\u001b[0m results_df\n",
      "\u001b[0;31mNameError\u001b[0m: name 'add_result' is not defined"
     ]
    }
   ],
   "source": [
    "# Add the results to your results dataframe or store them as needed\n",
    "add_result('GB Halving HPO', -halving_search_gb.best_score_, training_time)\n",
    "\n",
    "# Display or save your results dataframe\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc14126-b553-48a5-bfbd-3f747c222829",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_step = 'GB Halving'\n",
    "current_mae = -halving_search_gb.best_score_\n",
    "\n",
    "# Add the values to the DataFrame\n",
    "mae_df = mae_df.append({'Step': current_step, 'MAE': current_mae}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c67b20-02e3-448e-b024-94b5ce1e1130",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_mae_index = results_df['MAE'].idxmin()\n",
    "results_df.loc[min_mae_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71458389-448c-42d5-9cef-1be7aa8364ed",
   "metadata": {},
   "source": [
    "### 4.6. Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78aaec82-859a-4f0f-9d6f-77d57ad133dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "def objective(trial):\n",
    "    method = trial.suggest_categorical('method', ['tree', 'knn', 'random_forest', 'gradient_boosting'])\n",
    "    if method== 'tree':\n",
    "        max_depth=trial.suggest_int('max_depth', 2, 20)\n",
    "        min_samples_split= trial.suggest_int('min_samples_split', 50, 150, step=10)\n",
    "        params = {'max_depth': max_depth, 'min_samples_split': min_samples_split}\n",
    "        regr = DecisionTreeRegressor(random_state=random_state, **params)\n",
    "        \n",
    "    elif method=='knn':\n",
    "        n_neighbors= trial.suggest_int('n_neighbors',1,50)\n",
    "        weights = trial.suggest_categorical('weights', ['uniform', 'distance'])\n",
    "        algorithm = trial.suggest_categorical('algorithm', ['auto', 'ball_tree', 'kd_tree', 'brute'])\n",
    "        metric= trial.suggest_categorical('metric', ['minkowski','euclidean', 'chebyshev', 'manhattan'])\n",
    "\n",
    "        if metric == 'minkowski':\n",
    "            p= trial.suggest_float('p', 1.0,3.0)\n",
    "            params = {'n_neighbors': n_neighbors,'weights': weights,'algorithm': algorithm, 'metric': metric, 'p': p }\n",
    "        else:\n",
    "            params = {'n_neighbors': n_neighbors,'weights': weights,'algorithm': algorithm, 'metric': metric}\n",
    "        \n",
    "        regr = KNeighborsRegressor(**params)\n",
    "\n",
    "    elif method=='random_forest':\n",
    "        max_depth=trial.suggest_int('max_depth', 2, 20)\n",
    "        min_samples_split= trial.suggest_int('min_samples_split', 50, 150,step= 10)\n",
    "        n_estimators= trial.suggest_int('n_estimators', 50, 150,step=10)\n",
    "        max_features= trial.suggest_float('max_features', 0.2, 1.0)\n",
    "        params = {'max_depth': max_depth, 'min_samples_split': min_samples_split,'n_estimators': n_estimators, 'max_features': max_features }\n",
    "        regr = RandomForestRegressor(random_state=random_state, **params)\n",
    "\n",
    "    elif method=='gradient_boosting':\n",
    "        max_depth=trial.suggest_int('max_depth', 2, 20)\n",
    "        min_samples_split= trial.suggest_int('min_samples_split', 50, 150, step=10)\n",
    "        n_estimators= trial.suggest_int('n_estimators', 50, 150, step=10)\n",
    "        learning_rate= trial.suggest_float('learning_rate', 0.01, 0.21, step=0.02)\n",
    "        params = {'max_depth': max_depth, 'min_samples_split': min_samples_split,'n_estimators': n_estimators, 'learning_rate': learning_rate }\n",
    "        regr = GradientBoostingRegressor(random_state=random_state, **params)\n",
    "\n",
    "    scores= cross_val_score(regr, X_train, y_train, scoring= 'neg_mean_absolute_error',\n",
    "                            n_jobs=-1, cv=inner)\n",
    "    return scores.mean()\n",
    "\n",
    "budget=15\n",
    "sampler= optuna.samplers.TPESampler(seed=random_state)\n",
    "study = optuna.create_study(direction='maximize', sampler=sampler)\n",
    "start_time = time.time()\n",
    "\n",
    "study.optimize(objective,n_trials=budget)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd3ff8b-3554-472e-bc5c-8c09182f087a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate training time\n",
    "training_time = end_time - start_time\n",
    "print(study.best_params)\n",
    "print(-study.best_value)\n",
    "print(training_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c866a38-51cc-4204-9fca-5b2c07e100b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550dba40-04df-4ba0-8490-008a4977ccb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fd87d09-6faf-476d-bef7-6660aea3d2e6",
   "metadata": {},
   "source": [
    "## 5. Best model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbb6de5-36a3-4164-ba30-5f1162cae1dc",
   "metadata": {},
   "source": [
    "### 5.1. Estimation of the accuracy\n",
    "\n",
    "Using the best alternative (based on inner evaluation), make an estimation of the accuracy that the final model might get on future data (outer evaluation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd530bc3-32e4-48c1-bbe4-f91f5d06dcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=halving_search_gb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6f900d2-f4b2-4eef-8b05-1e08ae1e5b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 282.0748643062292\n"
     ]
    }
   ],
   "source": [
    "mae = mean_absolute_error(y_test, predictions)\n",
    "\n",
    "print(f\"MAE: {mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5983e72-f70f-4499-ba6f-32a7f165c527",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_step = 'final halving_search_gb'\n",
    "current_mae = mae\n",
    "\n",
    "# Add the values to the DataFrame\n",
    "mae_df = mae_df.append({'Step': current_step, 'MAE': current_mae}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a14e8d-6fee-4ff4-baee-0bb1f9fb3d43",
   "metadata": {},
   "source": [
    "### 5.2. Training final model and predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24322670-60b9-4545-b0d2-76a29d58f5ba",
   "metadata": {},
   "source": [
    "Train (using ALL THE DATA) and use it to make predictions on the “competition data”. Save both the final model and the competition predictions on files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46736cee-da37-41f6-9d8c-16042b3ef69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = wind_ava.drop('energy', axis=1)\n",
    "y=wind_ava['energy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ed87e2-4444-4929-8954-ef6058f43732",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbdfd686-a142-4ff6-9222-c9ec491ee948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters\n",
    "gb_params = {\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 3,\n",
    "    'min_samples_split': 5,\n",
    "    'n_estimators': 100\n",
    "}\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline_final = Pipeline([\n",
    "    ('imputer', IterativeImputer()), \n",
    "    ('scaler', RobustScaler()),\n",
    "    ('feature_selection', SelectKBest(k=150, score_func=mutual_info_regression)),  \n",
    "    ('gb', GradientBoostingRegressor(**gb_params))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c350fbf-d59f-44ca-b10c-aca7bbdab71b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;imputer&#x27;, IterativeImputer()), (&#x27;scaler&#x27;, RobustScaler()),\n",
       "                (&#x27;feature_selection&#x27;,\n",
       "                 SelectKBest(k=150,\n",
       "                             score_func=&lt;function mutual_info_regression at 0x1460c75e0&gt;)),\n",
       "                (&#x27;gb&#x27;, GradientBoostingRegressor(min_samples_split=5))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;imputer&#x27;, IterativeImputer()), (&#x27;scaler&#x27;, RobustScaler()),\n",
       "                (&#x27;feature_selection&#x27;,\n",
       "                 SelectKBest(k=150,\n",
       "                             score_func=&lt;function mutual_info_regression at 0x1460c75e0&gt;)),\n",
       "                (&#x27;gb&#x27;, GradientBoostingRegressor(min_samples_split=5))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">IterativeImputer</label><div class=\"sk-toggleable__content\"><pre>IterativeImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RobustScaler</label><div class=\"sk-toggleable__content\"><pre>RobustScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SelectKBest</label><div class=\"sk-toggleable__content\"><pre>SelectKBest(k=150, score_func=&lt;function mutual_info_regression at 0x1460c75e0&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(min_samples_split=5)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('imputer', IterativeImputer()), ('scaler', RobustScaler()),\n",
       "                ('feature_selection',\n",
       "                 SelectKBest(k=150,\n",
       "                             score_func=<function mutual_info_regression at 0x1460c75e0>)),\n",
       "                ('gb', GradientBoostingRegressor(min_samples_split=5))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_final.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ae2cc1d-1c72-460d-82d4-3695fbaec69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the model\n",
    "with open('final_model.pkl', 'wb') as file:\n",
    "    pickle.dump(pipeline_final, file)\n",
    "\n",
    "# Load the model\n",
    "with open('final_model.pkl', 'rb') as file:\n",
    "    loaded_model = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b88107ff-3743-49be-becc-817d6b8770e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_competition = pd.read_csv(\"/Users/pameladiaz/Desktop/GitHub/Big_Data_Intelligence/wind_competition.csv.gzip\", compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e66e1115-bfd8-4917-8b43-d76f5186d20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the transformed features\n",
    "v_wind_columns = wind_competition.columns[wind_competition.columns.str.startswith('v100.')]\n",
    "u_wind_columns = wind_competition.columns[wind_competition.columns.str.startswith('u100.')]\n",
    "\n",
    "# Iterate through pairs of u and v columns\n",
    "for u_col, v_col in zip(u_wind_columns, v_wind_columns):\n",
    "    # Extract u and v components\n",
    "    u_component = wind_competition[u_col]\n",
    "    v_component = wind_competition[v_col]\n",
    "\n",
    "    # Calculate wind speed\n",
    "    wind_speed_col = f\"wind_speed{u_col.split('.')[1]}\"\n",
    "    wind_competition[wind_speed_col] = np.sqrt(u_component**2 + v_component**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5218a07-6125-4bb3-a67b-9a556c6c3dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions = loaded_model.predict(wind_competition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3b6ac30-7d58-4ec0-a24c-bef626a9a76e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>p54.162.1</th>\n",
       "      <th>p54.162.2</th>\n",
       "      <th>p54.162.3</th>\n",
       "      <th>p54.162.4</th>\n",
       "      <th>p54.162.5</th>\n",
       "      <th>p54.162.6</th>\n",
       "      <th>...</th>\n",
       "      <th>wind_speed16</th>\n",
       "      <th>wind_speed17</th>\n",
       "      <th>wind_speed18</th>\n",
       "      <th>wind_speed19</th>\n",
       "      <th>wind_speed20</th>\n",
       "      <th>wind_speed21</th>\n",
       "      <th>wind_speed22</th>\n",
       "      <th>wind_speed23</th>\n",
       "      <th>wind_speed24</th>\n",
       "      <th>wind_speed25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.403131e+06</td>\n",
       "      <td>2.395445e+06</td>\n",
       "      <td>2.387755e+06</td>\n",
       "      <td>2.380065e+06</td>\n",
       "      <td>2.372380e+06</td>\n",
       "      <td>2.399548e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>7.734352</td>\n",
       "      <td>7.611616</td>\n",
       "      <td>7.490285</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.253692</td>\n",
       "      <td>7.751851</td>\n",
       "      <td>7.623800</td>\n",
       "      <td>7.496195</td>\n",
       "      <td>7.369751</td>\n",
       "      <td>7.244981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2.410306e+06</td>\n",
       "      <td>2.402394e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.386571e+06</td>\n",
       "      <td>2.378660e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2.195092</td>\n",
       "      <td>2.130851</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.373798</td>\n",
       "      <td>2.473778</td>\n",
       "      <td>2.408870</td>\n",
       "      <td>2.411927</td>\n",
       "      <td>2.481911</td>\n",
       "      <td>2.614772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2.434908e+06</td>\n",
       "      <td>2.426793e+06</td>\n",
       "      <td>2.418683e+06</td>\n",
       "      <td>2.410573e+06</td>\n",
       "      <td>2.402462e+06</td>\n",
       "      <td>2.431465e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>6.841988</td>\n",
       "      <td>6.659869</td>\n",
       "      <td>6.478858</td>\n",
       "      <td>6.298265</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.764951</td>\n",
       "      <td>6.589794</td>\n",
       "      <td>6.415657</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.069002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2.447112e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.431027e+06</td>\n",
       "      <td>2.422984e+06</td>\n",
       "      <td>2.414942e+06</td>\n",
       "      <td>2.443696e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>4.941264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.791060</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.646712</td>\n",
       "      <td>4.896041</td>\n",
       "      <td>4.821728</td>\n",
       "      <td>4.749233</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.607770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.459695e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.443809e+06</td>\n",
       "      <td>2.435866e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.456252e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>4.535790</td>\n",
       "      <td>4.491883</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.363570</td>\n",
       "      <td>4.504683</td>\n",
       "      <td>4.457223</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.364629</td>\n",
       "      <td>4.319119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 579 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  day  hour     p54.162.1     p54.162.2     p54.162.3  \\\n",
       "0  2010      1    1     0  2.403131e+06  2.395445e+06  2.387755e+06   \n",
       "1  2010      1    1     6  2.410306e+06  2.402394e+06           NaN   \n",
       "2  2010      1    1    12  2.434908e+06  2.426793e+06  2.418683e+06   \n",
       "3  2010      1    1    18  2.447112e+06           NaN  2.431027e+06   \n",
       "4  2010      1    2     0  2.459695e+06           NaN  2.443809e+06   \n",
       "\n",
       "      p54.162.4     p54.162.5     p54.162.6  ...  wind_speed16  wind_speed17  \\\n",
       "0  2.380065e+06  2.372380e+06  2.399548e+06  ...      7.734352      7.611616   \n",
       "1  2.386571e+06  2.378660e+06           NaN  ...      2.195092      2.130851   \n",
       "2  2.410573e+06  2.402462e+06  2.431465e+06  ...      6.841988      6.659869   \n",
       "3  2.422984e+06  2.414942e+06  2.443696e+06  ...      4.941264           NaN   \n",
       "4  2.435866e+06           NaN  2.456252e+06  ...      4.535790      4.491883   \n",
       "\n",
       "   wind_speed18  wind_speed19  wind_speed20  wind_speed21  wind_speed22  \\\n",
       "0      7.490285           NaN      7.253692      7.751851      7.623800   \n",
       "1           NaN           NaN      2.373798      2.473778      2.408870   \n",
       "2      6.478858      6.298265           NaN      6.764951      6.589794   \n",
       "3      4.791060           NaN      4.646712      4.896041      4.821728   \n",
       "4           NaN           NaN      4.363570      4.504683      4.457223   \n",
       "\n",
       "   wind_speed23  wind_speed24  wind_speed25  \n",
       "0      7.496195      7.369751      7.244981  \n",
       "1      2.411927      2.481911      2.614772  \n",
       "2      6.415657           NaN      6.069002  \n",
       "3      4.749233           NaN      4.607770  \n",
       "4           NaN      4.364629      4.319119  \n",
       "\n",
       "[5 rows x 579 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wind_competition.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33df89fe-63f4-4255-a61a-7738cd58ffff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([688.44711654, 160.41168528, 600.72944373, ..., 261.51935728,\n",
       "       149.03236724, 153.64375612])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a89f1a-28a3-427d-a483-11859962bdf4",
   "metadata": {},
   "source": [
    "### 5.3. FLAML library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81faa023-8bbc-46e0-afc8-ba81fa97b688",
   "metadata": {},
   "source": [
    "FLAML is a lightweight Python library for efficient automation of machine learning and AI operations. It automates workflow based on large language models, machine learning models, etc. and optimizes their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2b58e7-981a-4201-92bd-d6920d71d856",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flaml import AutoML\n",
    "automl = AutoML()\n",
    "automl.fit(X_train, y_train, task=\"classification\", time_budget=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ffcbca-7122-4317-9f97-fd497937ef1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5019eaaf-c78f-4079-a6c6-9c4c5dce9c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p59.162.1</th>\n",
       "      <th>p59.162.2</th>\n",
       "      <th>p59.162.3</th>\n",
       "      <th>p59.162.4</th>\n",
       "      <th>p59.162.5</th>\n",
       "      <th>p59.162.6</th>\n",
       "      <th>p59.162.7</th>\n",
       "      <th>p59.162.9</th>\n",
       "      <th>p59.162.11</th>\n",
       "      <th>p59.162.12</th>\n",
       "      <th>...</th>\n",
       "      <th>wind_speed16</th>\n",
       "      <th>wind_speed17</th>\n",
       "      <th>wind_speed18</th>\n",
       "      <th>wind_speed19</th>\n",
       "      <th>wind_speed20</th>\n",
       "      <th>wind_speed21</th>\n",
       "      <th>wind_speed22</th>\n",
       "      <th>wind_speed23</th>\n",
       "      <th>wind_speed24</th>\n",
       "      <th>wind_speed25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.400898e+06</td>\n",
       "      <td>1.405015e+06</td>\n",
       "      <td>1.408953e+06</td>\n",
       "      <td>1.413070e+06</td>\n",
       "      <td>1.417008e+06</td>\n",
       "      <td>1.389443e+06</td>\n",
       "      <td>1.393023e+06</td>\n",
       "      <td>1.400362e+06</td>\n",
       "      <td>1.380314e+06</td>\n",
       "      <td>1.383536e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>5.134636</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.393808</td>\n",
       "      <td>5.137268</td>\n",
       "      <td>4.948249</td>\n",
       "      <td>4.760744</td>\n",
       "      <td>4.574870</td>\n",
       "      <td>4.389944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.167130e+06</td>\n",
       "      <td>1.171426e+06</td>\n",
       "      <td>1.175722e+06</td>\n",
       "      <td>1.180018e+06</td>\n",
       "      <td>1.184314e+06</td>\n",
       "      <td>1.155674e+06</td>\n",
       "      <td>1.159433e+06</td>\n",
       "      <td>1.167130e+06</td>\n",
       "      <td>1.146367e+06</td>\n",
       "      <td>1.149946e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>5.298553</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.869726</td>\n",
       "      <td>4.655077</td>\n",
       "      <td>4.440835</td>\n",
       "      <td>5.300003</td>\n",
       "      <td>5.085998</td>\n",
       "      <td>4.872320</td>\n",
       "      <td>4.658335</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.114147e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.115758e+06</td>\n",
       "      <td>1.116653e+06</td>\n",
       "      <td>1.104661e+06</td>\n",
       "      <td>1.105377e+06</td>\n",
       "      <td>1.106450e+06</td>\n",
       "      <td>1.098038e+06</td>\n",
       "      <td>1.098396e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>5.587899</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.529130</td>\n",
       "      <td>5.324473</td>\n",
       "      <td>5.122190</td>\n",
       "      <td>4.922326</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.090699e+06</td>\n",
       "      <td>1.090878e+06</td>\n",
       "      <td>1.091057e+06</td>\n",
       "      <td>1.091236e+06</td>\n",
       "      <td>1.091594e+06</td>\n",
       "      <td>1.082644e+06</td>\n",
       "      <td>1.082644e+06</td>\n",
       "      <td>1.082823e+06</td>\n",
       "      <td>1.076200e+06</td>\n",
       "      <td>1.076200e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>4.779456</td>\n",
       "      <td>4.715311</td>\n",
       "      <td>4.655777</td>\n",
       "      <td>4.600019</td>\n",
       "      <td>4.549180</td>\n",
       "      <td>4.698198</td>\n",
       "      <td>4.634036</td>\n",
       "      <td>4.573135</td>\n",
       "      <td>4.516475</td>\n",
       "      <td>4.463542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.093563e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.081749e+06</td>\n",
       "      <td>1.077811e+06</td>\n",
       "      <td>1.085329e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.078885e+06</td>\n",
       "      <td>1.074947e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>3.941046</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.917355</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.851946</td>\n",
       "      <td>3.843097</td>\n",
       "      <td>3.836565</td>\n",
       "      <td>3.832704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3644</th>\n",
       "      <td>8.506655e+05</td>\n",
       "      <td>8.427897e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.272171e+05</td>\n",
       "      <td>8.193413e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.171933e+05</td>\n",
       "      <td>8.023367e+05</td>\n",
       "      <td>8.043056e+05</td>\n",
       "      <td>7.969668e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.471601</td>\n",
       "      <td>7.279755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.895840</td>\n",
       "      <td>7.371665</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.981368</td>\n",
       "      <td>6.786564</td>\n",
       "      <td>6.591311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3645</th>\n",
       "      <td>1.327868e+06</td>\n",
       "      <td>1.311759e+06</td>\n",
       "      <td>1.295828e+06</td>\n",
       "      <td>1.279718e+06</td>\n",
       "      <td>1.263609e+06</td>\n",
       "      <td>1.294575e+06</td>\n",
       "      <td>1.278644e+06</td>\n",
       "      <td>1.246783e+06</td>\n",
       "      <td>1.268263e+06</td>\n",
       "      <td>1.252511e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.912081</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.633936</td>\n",
       "      <td>6.496771</td>\n",
       "      <td>6.868302</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.577254</td>\n",
       "      <td>6.433403</td>\n",
       "      <td>6.290071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3646</th>\n",
       "      <td>1.630013e+06</td>\n",
       "      <td>1.622495e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.607460e+06</td>\n",
       "      <td>1.599942e+06</td>\n",
       "      <td>1.618199e+06</td>\n",
       "      <td>1.609966e+06</td>\n",
       "      <td>1.593319e+06</td>\n",
       "      <td>1.608713e+06</td>\n",
       "      <td>1.599942e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>5.251092</td>\n",
       "      <td>5.224762</td>\n",
       "      <td>5.200617</td>\n",
       "      <td>5.177566</td>\n",
       "      <td>5.155690</td>\n",
       "      <td>5.070743</td>\n",
       "      <td>5.042703</td>\n",
       "      <td>5.016349</td>\n",
       "      <td>4.991320</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3647</th>\n",
       "      <td>4.058611e+05</td>\n",
       "      <td>4.051451e+05</td>\n",
       "      <td>4.042501e+05</td>\n",
       "      <td>4.035342e+05</td>\n",
       "      <td>4.028182e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.004912e+05</td>\n",
       "      <td>3.990593e+05</td>\n",
       "      <td>3.976273e+05</td>\n",
       "      <td>3.969113e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.655181</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.487387</td>\n",
       "      <td>2.663482</td>\n",
       "      <td>2.607470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.495662</td>\n",
       "      <td>2.439739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3648</th>\n",
       "      <td>4.966120e+05</td>\n",
       "      <td>4.921371e+05</td>\n",
       "      <td>4.874832e+05</td>\n",
       "      <td>4.828293e+05</td>\n",
       "      <td>4.781754e+05</td>\n",
       "      <td>4.912421e+05</td>\n",
       "      <td>4.867672e+05</td>\n",
       "      <td>4.774594e+05</td>\n",
       "      <td>4.869462e+05</td>\n",
       "      <td>4.824713e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.639209</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.736581</td>\n",
       "      <td>2.786005</td>\n",
       "      <td>2.836004</td>\n",
       "      <td>2.570666</td>\n",
       "      <td>2.615252</td>\n",
       "      <td>2.660920</td>\n",
       "      <td>2.706500</td>\n",
       "      <td>2.752172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3649 rows × 250 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         p59.162.1     p59.162.2     p59.162.3     p59.162.4     p59.162.5  \\\n",
       "0     1.400898e+06  1.405015e+06  1.408953e+06  1.413070e+06  1.417008e+06   \n",
       "1     1.167130e+06  1.171426e+06  1.175722e+06  1.180018e+06  1.184314e+06   \n",
       "2              NaN  1.114147e+06           NaN  1.115758e+06  1.116653e+06   \n",
       "3     1.090699e+06  1.090878e+06  1.091057e+06  1.091236e+06  1.091594e+06   \n",
       "4     1.093563e+06           NaN           NaN  1.081749e+06  1.077811e+06   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "3644  8.506655e+05  8.427897e+05           NaN  8.272171e+05  8.193413e+05   \n",
       "3645  1.327868e+06  1.311759e+06  1.295828e+06  1.279718e+06  1.263609e+06   \n",
       "3646  1.630013e+06  1.622495e+06           NaN  1.607460e+06  1.599942e+06   \n",
       "3647  4.058611e+05  4.051451e+05  4.042501e+05  4.035342e+05  4.028182e+05   \n",
       "3648  4.966120e+05  4.921371e+05  4.874832e+05  4.828293e+05  4.781754e+05   \n",
       "\n",
       "         p59.162.6     p59.162.7     p59.162.9    p59.162.11    p59.162.12  \\\n",
       "0     1.389443e+06  1.393023e+06  1.400362e+06  1.380314e+06  1.383536e+06   \n",
       "1     1.155674e+06  1.159433e+06  1.167130e+06  1.146367e+06  1.149946e+06   \n",
       "2     1.104661e+06  1.105377e+06  1.106450e+06  1.098038e+06  1.098396e+06   \n",
       "3     1.082644e+06  1.082644e+06  1.082823e+06  1.076200e+06  1.076200e+06   \n",
       "4     1.085329e+06           NaN           NaN  1.078885e+06  1.074947e+06   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "3644           NaN  8.171933e+05  8.023367e+05  8.043056e+05  7.969668e+05   \n",
       "3645  1.294575e+06  1.278644e+06  1.246783e+06  1.268263e+06  1.252511e+06   \n",
       "3646  1.618199e+06  1.609966e+06  1.593319e+06  1.608713e+06  1.599942e+06   \n",
       "3647           NaN  4.004912e+05  3.990593e+05  3.976273e+05  3.969113e+05   \n",
       "3648  4.912421e+05  4.867672e+05  4.774594e+05  4.869462e+05  4.824713e+05   \n",
       "\n",
       "      ...  wind_speed16  wind_speed17  wind_speed18  wind_speed19  \\\n",
       "0     ...      5.134636           NaN           NaN           NaN   \n",
       "1     ...      5.298553           NaN      4.869726      4.655077   \n",
       "2     ...      5.587899           NaN           NaN           NaN   \n",
       "3     ...      4.779456      4.715311      4.655777      4.600019   \n",
       "4     ...      3.941046           NaN           NaN      3.917355   \n",
       "...   ...           ...           ...           ...           ...   \n",
       "3644  ...           NaN      7.471601      7.279755           NaN   \n",
       "3645  ...           NaN      6.912081           NaN      6.633936   \n",
       "3646  ...      5.251092      5.224762      5.200617      5.177566   \n",
       "3647  ...           NaN      2.655181           NaN           NaN   \n",
       "3648  ...      2.639209           NaN      2.736581      2.786005   \n",
       "\n",
       "      wind_speed20  wind_speed21  wind_speed22  wind_speed23  wind_speed24  \\\n",
       "0         4.393808      5.137268      4.948249      4.760744      4.574870   \n",
       "1         4.440835      5.300003      5.085998      4.872320      4.658335   \n",
       "2              NaN      5.529130      5.324473      5.122190      4.922326   \n",
       "3         4.549180      4.698198      4.634036      4.573135      4.516475   \n",
       "4              NaN           NaN      3.851946      3.843097      3.836565   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "3644      6.895840      7.371665           NaN      6.981368      6.786564   \n",
       "3645      6.496771      6.868302           NaN      6.577254      6.433403   \n",
       "3646      5.155690      5.070743      5.042703      5.016349      4.991320   \n",
       "3647      2.487387      2.663482      2.607470           NaN      2.495662   \n",
       "3648      2.836004      2.570666      2.615252      2.660920      2.706500   \n",
       "\n",
       "      wind_speed25  \n",
       "0         4.389944  \n",
       "1              NaN  \n",
       "2              NaN  \n",
       "3         4.463542  \n",
       "4         3.832704  \n",
       "...            ...  \n",
       "3644      6.591311  \n",
       "3645      6.290071  \n",
       "3646           NaN  \n",
       "3647      2.439739  \n",
       "3648      2.752172  \n",
       "\n",
       "[3649 rows x 250 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select only the headers from the original DataFrame\n",
    "selected_feature_headers = X_selected_features.columns\n",
    "\n",
    "# Create a new DataFrame using the selected headers and columns of X_train\n",
    "X_prueba = pd.DataFrame(X_train, columns=selected_feature_headers)\n",
    "X_prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c8b5807-4e82-41db-84a7-ddf20a7910db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p59.162.1</th>\n",
       "      <th>p59.162.2</th>\n",
       "      <th>p59.162.3</th>\n",
       "      <th>p59.162.4</th>\n",
       "      <th>p59.162.5</th>\n",
       "      <th>p59.162.6</th>\n",
       "      <th>p59.162.7</th>\n",
       "      <th>p59.162.9</th>\n",
       "      <th>p59.162.11</th>\n",
       "      <th>p59.162.12</th>\n",
       "      <th>...</th>\n",
       "      <th>wind_speed16</th>\n",
       "      <th>wind_speed17</th>\n",
       "      <th>wind_speed18</th>\n",
       "      <th>wind_speed19</th>\n",
       "      <th>wind_speed20</th>\n",
       "      <th>wind_speed21</th>\n",
       "      <th>wind_speed22</th>\n",
       "      <th>wind_speed23</th>\n",
       "      <th>wind_speed24</th>\n",
       "      <th>wind_speed25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3649</th>\n",
       "      <td>7.187457e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.911803e+05</td>\n",
       "      <td>6.775767e+05</td>\n",
       "      <td>6.637940e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.006671e+05</td>\n",
       "      <td>6.734598e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.974452e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>4.860973</td>\n",
       "      <td>4.804251</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.691537</td>\n",
       "      <td>4.635573</td>\n",
       "      <td>4.805741</td>\n",
       "      <td>4.750617</td>\n",
       "      <td>4.695948</td>\n",
       "      <td>4.641535</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3650</th>\n",
       "      <td>1.064565e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.025365e+06</td>\n",
       "      <td>1.005676e+06</td>\n",
       "      <td>9.861653e+05</td>\n",
       "      <td>1.060807e+06</td>\n",
       "      <td>1.041117e+06</td>\n",
       "      <td>1.002096e+06</td>\n",
       "      <td>1.057764e+06</td>\n",
       "      <td>1.038253e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>6.398697</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.839055</td>\n",
       "      <td>5.653117</td>\n",
       "      <td>6.311038</td>\n",
       "      <td>6.128136</td>\n",
       "      <td>5.945880</td>\n",
       "      <td>5.763317</td>\n",
       "      <td>5.580927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3651</th>\n",
       "      <td>1.302988e+06</td>\n",
       "      <td>1.283656e+06</td>\n",
       "      <td>1.264325e+06</td>\n",
       "      <td>1.244993e+06</td>\n",
       "      <td>1.225662e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.281687e+06</td>\n",
       "      <td>1.242666e+06</td>\n",
       "      <td>1.299766e+06</td>\n",
       "      <td>1.280076e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>9.014981</td>\n",
       "      <td>8.627820</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.854394</td>\n",
       "      <td>7.468168</td>\n",
       "      <td>8.891314</td>\n",
       "      <td>8.505001</td>\n",
       "      <td>8.118789</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3652</th>\n",
       "      <td>1.979592e+06</td>\n",
       "      <td>1.914616e+06</td>\n",
       "      <td>1.849641e+06</td>\n",
       "      <td>1.784665e+06</td>\n",
       "      <td>1.719690e+06</td>\n",
       "      <td>1.985499e+06</td>\n",
       "      <td>1.920165e+06</td>\n",
       "      <td>1.789319e+06</td>\n",
       "      <td>1.990331e+06</td>\n",
       "      <td>1.924461e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>11.676951</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.735430</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.805992</td>\n",
       "      <td>11.542441</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.604058</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.676562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3653</th>\n",
       "      <td>2.315567e+06</td>\n",
       "      <td>2.285137e+06</td>\n",
       "      <td>2.254708e+06</td>\n",
       "      <td>2.224458e+06</td>\n",
       "      <td>2.194029e+06</td>\n",
       "      <td>2.323264e+06</td>\n",
       "      <td>2.292834e+06</td>\n",
       "      <td>2.231976e+06</td>\n",
       "      <td>2.329528e+06</td>\n",
       "      <td>2.298920e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>9.273835</td>\n",
       "      <td>9.063486</td>\n",
       "      <td>8.862578</td>\n",
       "      <td>8.671693</td>\n",
       "      <td>8.492027</td>\n",
       "      <td>9.168775</td>\n",
       "      <td>8.959526</td>\n",
       "      <td>8.759649</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.390777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4743</th>\n",
       "      <td>3.611317e+06</td>\n",
       "      <td>3.699920e+06</td>\n",
       "      <td>3.788523e+06</td>\n",
       "      <td>3.877126e+06</td>\n",
       "      <td>3.965729e+06</td>\n",
       "      <td>3.674324e+06</td>\n",
       "      <td>3.764179e+06</td>\n",
       "      <td>3.943533e+06</td>\n",
       "      <td>3.724442e+06</td>\n",
       "      <td>3.815014e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>11.698059</td>\n",
       "      <td>11.580590</td>\n",
       "      <td>11.463558</td>\n",
       "      <td>11.346166</td>\n",
       "      <td>11.228817</td>\n",
       "      <td>11.704657</td>\n",
       "      <td>11.583126</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.340611</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4744</th>\n",
       "      <td>2.514968e+06</td>\n",
       "      <td>2.593368e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.828390e+06</td>\n",
       "      <td>2.554705e+06</td>\n",
       "      <td>2.633821e+06</td>\n",
       "      <td>2.792053e+06</td>\n",
       "      <td>2.586029e+06</td>\n",
       "      <td>2.665861e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>10.444271</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.565530</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.696277</td>\n",
       "      <td>10.478256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.580514</td>\n",
       "      <td>10.635079</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4745</th>\n",
       "      <td>2.073207e+06</td>\n",
       "      <td>2.128158e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.238062e+06</td>\n",
       "      <td>2.293192e+06</td>\n",
       "      <td>2.110975e+06</td>\n",
       "      <td>2.166821e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.197430e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>4.515215</td>\n",
       "      <td>4.541995</td>\n",
       "      <td>4.569241</td>\n",
       "      <td>4.596944</td>\n",
       "      <td>4.625096</td>\n",
       "      <td>4.418757</td>\n",
       "      <td>4.446906</td>\n",
       "      <td>4.475020</td>\n",
       "      <td>4.503584</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4746</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.359908e+06</td>\n",
       "      <td>1.358297e+06</td>\n",
       "      <td>1.356687e+06</td>\n",
       "      <td>1.355076e+06</td>\n",
       "      <td>1.371543e+06</td>\n",
       "      <td>1.370111e+06</td>\n",
       "      <td>1.367247e+06</td>\n",
       "      <td>1.379598e+06</td>\n",
       "      <td>1.378345e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>9.462473</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.976908</td>\n",
       "      <td>9.502296</td>\n",
       "      <td>9.123884</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.383905</td>\n",
       "      <td>8.024426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4747</th>\n",
       "      <td>1.323572e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.329300e+06</td>\n",
       "      <td>1.332164e+06</td>\n",
       "      <td>1.335028e+06</td>\n",
       "      <td>1.339682e+06</td>\n",
       "      <td>1.342188e+06</td>\n",
       "      <td>1.347021e+06</td>\n",
       "      <td>1.352570e+06</td>\n",
       "      <td>1.354718e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>7.425060</td>\n",
       "      <td>7.361131</td>\n",
       "      <td>7.297110</td>\n",
       "      <td>7.233272</td>\n",
       "      <td>7.169348</td>\n",
       "      <td>7.413167</td>\n",
       "      <td>7.340337</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.194610</td>\n",
       "      <td>7.121851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1099 rows × 250 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         p59.162.1     p59.162.2     p59.162.3     p59.162.4     p59.162.5  \\\n",
       "3649  7.187457e+05           NaN  6.911803e+05  6.775767e+05  6.637940e+05   \n",
       "3650  1.064565e+06           NaN  1.025365e+06  1.005676e+06  9.861653e+05   \n",
       "3651  1.302988e+06  1.283656e+06  1.264325e+06  1.244993e+06  1.225662e+06   \n",
       "3652  1.979592e+06  1.914616e+06  1.849641e+06  1.784665e+06  1.719690e+06   \n",
       "3653  2.315567e+06  2.285137e+06  2.254708e+06  2.224458e+06  2.194029e+06   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "4743  3.611317e+06  3.699920e+06  3.788523e+06  3.877126e+06  3.965729e+06   \n",
       "4744  2.514968e+06  2.593368e+06           NaN           NaN  2.828390e+06   \n",
       "4745  2.073207e+06  2.128158e+06           NaN  2.238062e+06  2.293192e+06   \n",
       "4746           NaN  1.359908e+06  1.358297e+06  1.356687e+06  1.355076e+06   \n",
       "4747  1.323572e+06           NaN  1.329300e+06  1.332164e+06  1.335028e+06   \n",
       "\n",
       "         p59.162.6     p59.162.7     p59.162.9    p59.162.11    p59.162.12  \\\n",
       "3649           NaN  7.006671e+05  6.734598e+05           NaN  6.974452e+05   \n",
       "3650  1.060807e+06  1.041117e+06  1.002096e+06  1.057764e+06  1.038253e+06   \n",
       "3651           NaN  1.281687e+06  1.242666e+06  1.299766e+06  1.280076e+06   \n",
       "3652  1.985499e+06  1.920165e+06  1.789319e+06  1.990331e+06  1.924461e+06   \n",
       "3653  2.323264e+06  2.292834e+06  2.231976e+06  2.329528e+06  2.298920e+06   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "4743  3.674324e+06  3.764179e+06  3.943533e+06  3.724442e+06  3.815014e+06   \n",
       "4744  2.554705e+06  2.633821e+06  2.792053e+06  2.586029e+06  2.665861e+06   \n",
       "4745  2.110975e+06  2.166821e+06           NaN           NaN  2.197430e+06   \n",
       "4746  1.371543e+06  1.370111e+06  1.367247e+06  1.379598e+06  1.378345e+06   \n",
       "4747  1.339682e+06  1.342188e+06  1.347021e+06  1.352570e+06  1.354718e+06   \n",
       "\n",
       "      ...  wind_speed16  wind_speed17  wind_speed18  wind_speed19  \\\n",
       "3649  ...      4.860973      4.804251           NaN      4.691537   \n",
       "3650  ...      6.398697           NaN           NaN      5.839055   \n",
       "3651  ...      9.014981      8.627820           NaN      7.854394   \n",
       "3652  ...     11.676951           NaN     10.735430           NaN   \n",
       "3653  ...      9.273835      9.063486      8.862578      8.671693   \n",
       "...   ...           ...           ...           ...           ...   \n",
       "4743  ...     11.698059     11.580590     11.463558     11.346166   \n",
       "4744  ...     10.444271           NaN     10.565530           NaN   \n",
       "4745  ...      4.515215      4.541995      4.569241      4.596944   \n",
       "4746  ...      9.462473           NaN           NaN           NaN   \n",
       "4747  ...      7.425060      7.361131      7.297110      7.233272   \n",
       "\n",
       "      wind_speed20  wind_speed21  wind_speed22  wind_speed23  wind_speed24  \\\n",
       "3649      4.635573      4.805741      4.750617      4.695948      4.641535   \n",
       "3650      5.653117      6.311038      6.128136      5.945880      5.763317   \n",
       "3651      7.468168      8.891314      8.505001      8.118789           NaN   \n",
       "3652      9.805992     11.542441           NaN     10.604058           NaN   \n",
       "3653      8.492027      9.168775      8.959526      8.759649           NaN   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "4743     11.228817     11.704657     11.583126           NaN     11.340611   \n",
       "4744     10.696277     10.478256           NaN     10.580514     10.635079   \n",
       "4745      4.625096      4.418757      4.446906      4.475020      4.503584   \n",
       "4746      7.976908      9.502296      9.123884           NaN      8.383905   \n",
       "4747      7.169348      7.413167      7.340337           NaN      7.194610   \n",
       "\n",
       "      wind_speed25  \n",
       "3649           NaN  \n",
       "3650      5.580927  \n",
       "3651           NaN  \n",
       "3652      9.676562  \n",
       "3653      8.390777  \n",
       "...            ...  \n",
       "4743           NaN  \n",
       "4744           NaN  \n",
       "4745           NaN  \n",
       "4746      8.024426  \n",
       "4747      7.121851  \n",
       "\n",
       "[1099 rows x 250 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new DataFrame using the selected headers and columns of X_train\n",
    "X_prueba_test = pd.DataFrame(X_test, columns=selected_feature_headers)\n",
    "X_prueba_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2305ffcb-fff9-4bf3-8c09-7c9e713d9858",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
